# ğŸ¢ Company Junction â€” Deduplication Pipeline & UI

> **Fast, reproducible pipeline for finding duplicate Salesforce records, picking a primary, and producing reviewâ€‘ready files and parquet artifacts.**

ğŸ“‹ **This README is taskâ€‘oriented**: plainâ€‘English explanations and copyâ€‘pasteable commands.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## [NAVIGATION] ğŸ“‘ Quick Navigation

| ğŸ¯ **Get Started** | âš™ï¸ **Configuration** | ğŸ”§ **Advanced** |
|-------------------|---------------------|-----------------|
| [ğŸš€ What you get](#-what-you-get) | [ğŸƒâ€â™‚ï¸ Run the pipeline](#-run-the-pipeline-quick-starts) | [ğŸ§¹ Cleanup & Run Management](#-cleanup--run-management) |
| [ğŸ“‹ Prerequisites](#-prerequisites) | [âš™ï¸ All flags & examples](#ï¸-all-flags--examples) | [ğŸ” Understanding stages & artifacts](#-understanding-stages--artifacts) |
| [ğŸ’¾ Install](#-install) | [ğŸ”„ Backend parity](#-backend-parity) | [ğŸ› ï¸ Troubleshooting](#ï¸-troubleshooting) |
| [ğŸ“ Your data](#-your-data) | | [â“ FAQ](#-faq) |

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## [GET STARTED] ğŸ¯ What you get
_Key outputs from the pipeline_
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

> **âœ¨ Key Outputs**

- ğŸ“„ **Review file** (CSV + Parquet) with dispositions: `Keep`, `Update`, `Delete`, `Verify`
- ğŸ“Š **Group stats** parquet for snappy UI experience  
- ğŸ” **Intermediate artifacts** for debugging and audit
- ğŸ–¥ï¸ **Streamlit UI** to explore/verify results (readâ€‘only)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## [GET STARTED] ğŸ“‹ Prerequisites
_Required before first run_
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

> **ğŸ–¥ï¸ System Requirements**

- âœ… **macOS / Linux** (Windows WSL works)
- ğŸ **Python 3.10+**
- ğŸ”§ **(Optional)** Salesforce CLI for future SFDC operations

> ğŸ’¡ **We strongly recommend a virtual environment per project.**

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## [GET STARTED] ğŸ’¾ Install
_One-time setup process_
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

> **ğŸš€ Quick Setup**

```bash
# 1ï¸âƒ£ Create and activate a venv
python -m venv .venv
source .venv/bin/activate

# 2ï¸âƒ£ Install dependencies
python -m pip install -r requirements.txt

# 3ï¸âƒ£ (Optional) editable install for local imports
python -m pip install -e .
```

> âš ï¸ **Tip**: If you switch Python versions, recreate the venv.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## [GET STARTED] ğŸ“ Your data
_Where to put your input files_
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

> **ğŸ“‚ Data Placement**

Place your Salesforce export(s) in `data/raw/`. 

**Supported formats**: CSV, XLSX, and XLS

> ğŸ”„ **Auto-mapping**: The pipeline autoâ€‘maps columns, but you can override names at the CLI (see **All flags** below).  
> ğŸ’¾ **Schema decisions** are saved perâ€‘run to `data/processed/{run_id}/schema_mapping.json`.

## [CONFIGURATION] ğŸƒâ€â™‚ï¸ Run the pipeline (quick starts)
_Copy-paste examples for immediate use_
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

> **ğŸš€ Ready-to-use examples** â€” safe to copy/paste. Replace the input path as needed.

> âš ï¸ **macOS Users**: Clamp BLAS threads to prevent oversubscription:
```bash
export OMP_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 VECLIB_MAXIMUM_THREADS=1 NUMEXPR_NUM_THREADS=1
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ¯ A) Minimal endâ€‘toâ€‘end run

```bash
RUN_ID="cj$(date +%Y%m%d%H%M%S)"
python src/cleaning.py \
  --input data/raw/company_junction_range_01.csv \
  --outdir data/processed \
  --config config/settings.yaml \
  --run-id "$RUN_ID"
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ“Š B) With progress bars and deterministic fresh run

```bash
RUN_ID="cj$(date +%Y%m%d%H%M%S)"
python src/cleaning.py \
  --input data/raw/company_junction_range_01.csv \
  --outdir data/processed \
  --config config/settings.yaml \
  --run-id "$RUN_ID" \
  --progress \
  --no-resume
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### âš¡ C) Performanceâ€‘tuned (Apple Silicon example)

```bash
source .venv/bin/activate
export OMP_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 VECLIB_MAXIMUM_THREADS=1 NUMEXPR_NUM_THREADS=1
RUN_ID="cj$(date +%Y%m%d%H%M%S)"

python src/cleaning.py \
  --input data/raw/company_junction_range_01.csv \
  --outdir data/processed \
  --config config/settings.yaml \
  --run-id "$RUN_ID" \
  --workers 10 \
  --chunk-size 2000 \
  --parallel-backend loky \
  --progress \
  --no-resume
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ–¥ï¸ D) Launch the Streamlit UI

```bash
# ğŸ¯ Option 1: wrapper (preferred)
python run_streamlit.py

# ğŸ”§ Option 2: direct (Ctrl+C may show a CancelledError)
streamlit run app/main.py
```

## [CONFIGURATION] âš™ï¸ All flags & examples
_Complete command-line reference_
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

> **ğŸ“š Complete reference** â€” `python src/cleaning.py --help` lists everything. Here are the **common flags** with copyâ€‘paste examples.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ“¥ Inputs & basic control
_These are the most common flags you'll actually use._

| Flag | Description | Default |
|------|-------------|---------|
| `--input PATH` | ğŸ“„ **Required CSV/XLS(X)** | â€” |
| `--outdir DIR` | ğŸ“ Output root | `data/processed` |
| `--config PATH` | âš™ï¸ YAML settings | `config/settings.yaml` |
| `--run-id STR` | ğŸ·ï¸ Name the run; used for foldering & pointers | Auto-generated |

```bash
python src/cleaning.py \
  --input data/raw/my_export.csv \
  --outdir data/processed \
  --config config/settings.yaml \
  --run-id "cj_demo"
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ”„ Progress & resumes
_Control how the pipeline runs and resumes._

| Flag | Description |
|------|-------------|
| `--progress` | ğŸ“Š tqdm bars (if installed) |
| `--no-resume` | ğŸ”„ **Force fresh run** (ignore previous state) |
| `--resume-from STAGE` | ğŸ¯ Resume at a later stage |
| `--force` | âš ï¸ Allow resume even if inputs changed (hash mismatch) |
| `--state-path PATH` | ğŸ“„ Custom state file |

> **ğŸ¯ Valid `STAGE` values**: `normalization`, `filtering`, `candidate_generation`, `grouping`, `survivorship`, `disposition`, `alias_matching`, `final_output`

```bash
# Resume from grouping (skips earlier stages)
python src/cleaning.py --input data/raw/my_export.csv --outdir data/processed --config config/settings.yaml --run-id "cj_demo" --resume-from grouping
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ—‚ï¸ Column mapping (schema)
_Map your CSV headers to expected column names._

> **ğŸ”„ Resolution order**: CLI overrides â†’ filename template â†’ synonyms â†’ heuristics

```bash
# Map actual headers â†’ canonical names
python src/cleaning.py \
  --input data/raw/weird_headers.csv \
  --outdir data/processed \
  --config config/settings.yaml \
  --run-id "cj_map" \
  --col account_name="Account Name" account_id="Account ID"
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### âš¡ Parallelism & chunks
_Performance tuning for different system sizes._

| Flag | Description | Default |
|------|-------------|---------|
| `--workers N` | ğŸ‘¥ Process count | Auto |
| `--no-parallel` | ğŸ”’ **Singleâ€‘process** |
| `--parallel-backend {loky,threading}` | ğŸ”§ Backend | `loky` |
| `--chunk-size N` | ğŸ“¦ Chunk size for parallel operations | `1000` |

```bash
python src/cleaning.py \
  --input data/raw/my_export.csv \
  --outdir data/processed \
  --config config/settings.yaml \
  --run-id "cj_perf" \
  --workers 8 --chunk-size 1500 --parallel-backend loky
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ”§ Environment toggles (optional)

| Variable | Description |
|----------|-------------|
| `CJ_GROUP_STATS_PERSIST_ARTIFACTS=true\|false` | ğŸ“Š Force writing groupâ€‘stats artifacts |
| `CJ_GROUP_STATS_RUN_PARITY=true\|false` | ğŸ” Run pandas vs DuckDB parity check |

```bash
CJ_GROUP_STATS_PERSIST_ARTIFACTS=true CJ_GROUP_STATS_RUN_PARITY=true \
python src/cleaning.py --input data/raw/my_export.csv --outdir data/processed --config config/settings.yaml --run-id "cj_parity"
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ“ Logging

> **âš™ï¸ Logging defaults** come from `config/settings.yaml`:

```yaml
logging:
  level: "INFO"
  file: "pipeline.log"
```

> **ğŸ‘€ Tail logs** while a run executes:

```bash
tail -f pipeline.log
```

[â†‘ Back to top](#-company-junction--deduplication-pipeline--ui)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## [ADVANCED] ğŸ§¹ Cleanup & Run Management

> **ğŸ—‚ï¸ Pipeline creates run artifacts that can accumulate over time. Use the cleanup utility to manage them safely.**

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸš€ Quick Cleanup Commands

```bash
# ğŸ“‹ List all runs grouped by type
python tools/pipeline_cleanup.py --list

# ğŸ‘€ Preview what would be deleted (recommended first step)
python tools/pipeline_cleanup.py --delete-tests --dry-run
python tools/pipeline_cleanup.py --delete-prod --dry-run
python tools/pipeline_cleanup.py --delete-all --dry-run
python tools/pipeline_cleanup.py --delete-run RUN_ID --dry-run

# ğŸ—‘ï¸ Actually delete (requires confirmation)
python tools/pipeline_cleanup.py --delete-tests
python tools/pipeline_cleanup.py --delete-prod
python tools/pipeline_cleanup.py --delete-all
python tools/pipeline_cleanup.py --delete-run RUN_ID
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ·ï¸ Run Types

| Type | Description | Usage |
|------|-------------|-------|
| **`dev`** | ğŸ› ï¸ Development runs | Default |
| **`test`** | ğŸ§ª Test runs | `--run-type test` |
| **`prod`** | ğŸš€ Production runs | `--run-type prod` |

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ›¡ï¸ Safety Features

- âœ… **Dry-run by default** - Always preview before deleting
- âœ… **Confirmation prompts** - Explicit user confirmation required
- âœ… **Fuse protection** - Respects `PHASE1_DESTRUCTIVE_FUSE` environment variable
- âœ… **Running run protection** - Blocks deletion of active pipeline runs
- âœ… **Latest run protection** - Never deletes the latest successful run

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ–¥ï¸ Streamlit UI Integration

> **âš™ï¸ Run deletion** is available in the Streamlit UI under "âš™ï¸ Advanced: Maintenance" when:
- `ui.enable_run_deletion: true` in `config/settings.yaml`
- `ui.admin_mode: true` in `config/settings.yaml`

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ·ï¸ Setting Run Type

> **ğŸ¯ Use the `--run-type` flag** when running the pipeline:

```bash
# ğŸ› ï¸ Development run (default)
python src/cleaning.py --input data.csv --outdir data/processed

# ğŸ§ª Test run
python src/cleaning.py --input data.csv --outdir data/processed --run-type test

# ğŸš€ Production run
python src/cleaning.py --input data.csv --outdir data/processed --run-type prod
```

> **ğŸ’¾ The run type** is stored in both `review_meta.json` and `run_index.json` for cleanup operations.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ“Š Exit Codes

| Code | Meaning |
|------|---------|
| **0** | âœ… No candidates found for deletion |
| **2** | ğŸ‘€ Candidates found (dry-run mode) |
| **>0** | âŒ Errors occurred during execution |

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ”„ Legacy Run Handling

> **âš ï¸ Runs created before the run type system** are treated as `dev` runs with a warning logged:

```
WARNING: Legacy run cj20250905190659 missing run_type, treating as 'dev'
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ’¡ Best Practices

1. **ğŸ‘€ Always use `--dry-run` first** to preview what will be deleted
2. **ğŸ·ï¸ Use specific run types** when running the pipeline for easier cleanup
3. **ğŸš€ Keep production runs** longer than test runs
4. **ğŸ“Š Monitor disk usage** and clean up regularly
5. **ğŸ–¥ï¸ Use the Streamlit UI** for interactive cleanup when available

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ› ï¸ Troubleshooting

#### ğŸ”’ Permission Errors

> **If you encounter permission errors**, ensure the cleanup utility has write access:

```bash
# Check permissions
ls -la data/processed/
ls -la data/interim/

# Fix permissions if needed
chmod -R 755 data/processed/
chmod -R 755 data/interim/
```

#### ğŸ”¥ Fuse Disabled

> **If the fuse is disabled**, you'll see:

```
Delete runs disabled: Phase 1 destructive fuse not enabled
```

> **Enable it with:**

```bash
export PHASE1_DESTRUCTIVE_FUSE=true
```

#### ğŸ” Running Process Detection

> **If the utility incorrectly detects a running process**, check for active processes:

```bash
# Check for active cleaning.py processes
ps aux | grep cleaning.py
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ”„ Migration from Old Cleanup Script

> **âš ï¸ The old `tools/cleanup_test_artifacts.py` has been deprecated.** Use the new `pipeline_cleanup.py` instead:

```bash
# âŒ Old way (deprecated)
python tools/cleanup_test_artifacts.py --types test,dev --older-than 7

# âœ… New way (current)
python tools/pipeline_cleanup.py --delete-tests --dry-run
python tools/pipeline_cleanup.py --delete-tests
```

> **ğŸ“š See `deprecated/README.md`** for more migration information.

[â†‘ Back to top](#-company-junction--deduplication-pipeline--ui)

## [ADVANCED] ğŸ” Understanding stages & artifacts

> **ğŸ“ Each run creates `interim` and `processed` folders under your `--run-id`.**

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ”„ Pipeline Stages (in order)

| Stage | Description | Purpose |
|-------|-------------|---------|
| 1ï¸âƒ£ **normalization** | ğŸ§¹ Clean and tokenize names | Data preparation |
| 2ï¸âƒ£ **filtering** | ğŸ—‘ï¸ Drop empty/noisy names | Quality control |
| 3ï¸âƒ£ **candidate_generation** | ğŸ¯ Create & score candidate pairs | Similarity detection |
| 4ï¸âƒ£ **grouping** | ğŸ”— Unionâ€‘find with edgeâ€‘gating | Group formation |
| 5ï¸âƒ£ **survivorship** | ğŸ‘‘ Pick a single primary per group | Primary selection |
| 6ï¸âƒ£ **disposition** | ğŸ·ï¸ Classify each record | Decision making |
| 7ï¸âƒ£ **alias_matching** | ğŸ”— Produce alias crossâ€‘references | Relationship mapping |
| 8ï¸âƒ£ **final_output** | ğŸ“„ Write review files and summaries | Output generation |

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ“¦ Key Artifacts (typical)

| File | Description | Location |
|------|-------------|----------|
| ğŸ“„ **review_ready.csv** | Main review file with dispositions | `data/processed/{run_id}/` |
| âš¡ **review_ready.parquet** | Parquet version for performance | `data/processed/{run_id}/` |
| ğŸ“Š **group_stats.parquet** | Group-level statistics | `data/processed/{run_id}/` |
| ğŸ” **group_details.parquet** | Detailed group information | `data/processed/{run_id}/` |
| âš™ï¸ **review_meta.json** | Run metadata and configuration | `data/processed/{run_id}/` |
| ğŸ—‚ï¸ **interim files** | Intermediate files for debugging and resume | `data/interim/{run_id}/` |

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## [ADVANCED] ğŸ”„ Backend parity (why we run two engines sometimes)

> **ğŸ”§ The pipeline supports both pandas and DuckDB backends for different operations:**

| Backend | Use Case | Performance |
|---------|----------|-------------|
| **ğŸ¦† DuckDB** (default) | Fast analytics queries, group statistics, large dataset operations | âš¡ High |
| **ğŸ¼ pandas** | Complex data transformations, string processing, legacy compatibility | ğŸ”§ Flexible |

> **ğŸ” Parity validation** ensures both backends produce identical results. Enable with:
```bash
CJ_GROUP_STATS_RUN_PARITY=true python src/cleaning.py ...
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## [ADVANCED] ğŸ› ï¸ Troubleshooting

> **ğŸš¨ Common Issues & Solutions**

### ğŸ” **Adversarial False Positives (Production Blocker)**

If you're experiencing incorrect company groupings (e.g., "Apple Inc" being grouped with "Apple Bank Inc"), see the comprehensive troubleshooting plan:

**ğŸ“‹ [Phase 2.0.2 Adversarial False Positives Plan](docs/plans/Phase2.0.2-Adversarial-FalsePositives.md)**

This document provides:
- Root cause analysis of false-positive cases
- Detailed implementation strategy for distractor token handling
- Test plans and acceptance criteria
- Configuration options for fine-tuning similarity scoring

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### âŒ Common Issues

#### ğŸ”§ **Pipeline fails with "No module named 'src'"**
```bash
# Install in editable mode
python -m pip install -e .
```

#### ğŸ’¾ **Memory issues on large datasets**
```bash
# Reduce chunk size and workers
python src/cleaning.py --chunk-size 500 --workers 4 ...
```

#### ğŸ”„ **Resume fails with hash mismatch**
```bash
# Force resume (use with caution)
python src/cleaning.py --force --resume-from grouping ...
```

#### ğŸ–¥ï¸ **Streamlit UI shows "No runs found"**
- âœ… Check `data/processed/latest.json` points to a valid run
- âœ… Verify run artifacts exist in `data/processed/{run_id}/`

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### âš¡ Performance Tuning

#### ğŸ **For Apple Silicon (M1/M2)**
```bash
export OMP_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1 VECLIB_MAXIMUM_THREADS=1 NUMEXPR_NUM_THREADS=1
python src/cleaning.py --workers 10 --chunk-size 2000 --parallel-backend loky ...
```

#### ğŸ“Š **For large datasets (>100K records)**
```bash
python src/cleaning.py --workers 8 --chunk-size 1500 --parallel-backend loky ...
```

#### ğŸ“ **For small datasets (<10K records)**
```bash
python src/cleaning.py --no-parallel ...
```

[â†‘ Back to top](#-company-junction--deduplication-pipeline--ui)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## [REFERENCE] â“ FAQ

> **ğŸ¤” Frequently Asked Questions**

| Question | Answer |
|----------|--------|
| **ğŸ”„ Can I resume a failed pipeline run?** | âœ… Yes! Use `--resume-from STAGE` or let the pipeline auto-detect the resume point. |
| **ğŸ“„ What file formats are supported?** | ğŸ“Š CSV, XLSX, and XLS files. The pipeline auto-detects format and handles encoding. |
| **ğŸ—‚ï¸ How do I map custom column names?** | ğŸ¯ Use `--col` flags: `--col account_name="Company Name" account_id="ID"` |
| **ğŸ–¥ï¸ Can I run the pipeline without the UI?** | âœ… Yes! The pipeline produces review files that can be opened in Excel or any CSV viewer. |
| **ğŸ·ï¸ What's the difference between run types?** | ğŸ› ï¸ `dev` (default), ğŸ§ª `test`, and ğŸš€ `prod` runs are categorized for cleanup operations only. |
| **ğŸ§¹ How do I clean up old runs?** | ğŸ“‹ Use `python tools/pipeline_cleanup.py --list` to see runs, then `--delete-tests` or `--delete-all`. |

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## [REFERENCE] ğŸ¤ Contributing

> **ğŸš€ How to contribute to this project**

### ğŸ“‹ Steps to Contribute

1. **ğŸ´ Fork the repository**
2. **ğŸŒ¿ Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **âœ… Follow the coding standards**:
   - ğŸ¨ Run `black` for formatting
   - ğŸ” Run `ruff` for linting  
   - ğŸ”§ Run `mypy` for type checking
   - ğŸ§ª Run `pytest` for tests
4. **ğŸ’¾ Commit your changes**: `git commit -m 'Add amazing feature'`
5. **ğŸ“¤ Push to the branch**: `git push origin feature/amazing-feature`
6. **ğŸ”„ Open a Pull Request**

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

### ğŸ› ï¸ Development Setup

```bash
# Install development dependencies
python -m pip install -e ".[dev]"

# Run all checks
black src/ tests/
ruff check src/ tests/
mypy src/
pytest tests/
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

## [REFERENCE] ğŸ“„ License

> **ğŸ“œ This project is licensed under the MIT License** - see the [LICENSE](LICENSE) file for details.
