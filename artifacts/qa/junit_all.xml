<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="11" failures="39" skipped="19" tests="795" time="7.364" timestamp="2025-09-05T17:28:39.581016-07:00" hostname="Joe-Juneau-L218"><testcase classname="tests.contracts.test_parquet_contracts.TestParquetContracts" name="test_required_columns_exist" time="0.001"><failure message="KeyError: 'actual_columns'">self = &lt;tests.contracts.test_parquet_contracts.TestParquetContracts object at 0x103247560&gt;
artifact_paths = {'group_details_parquet': '/path/to/group_details.parquet', 'group_stats_parquet': '/path/to/group_stats.parquet', 'review_ready_parquet': '/path/to/review_ready.parquet'}

    def test_required_columns_exist(self, artifact_paths):
        """Test that all required columns exist in parquet files."""
        for parquet_type, required in REQUIRED_COLUMNS.items():
            if parquet_type in artifact_paths:
                file_path = artifact_paths[parquet_type]
                result = validate_parquet_schema(file_path, parquet_type)
    
                assert result["valid"], (
                    f"{parquet_type} schema validation failed: {result['error']}\n"
                    f"Required: {required}\n"
&gt;                   f"Actual: {result['actual_columns']}\n"
                               ^^^^^^^^^^^^^^^^^^^^^^^^
                    f"Missing: {result['missing_columns']}"
                )
E               KeyError: 'actual_columns'

tests/contracts/test_parquet_contracts.py:149: KeyError</failure></testcase><testcase classname="tests.contracts.test_parquet_contracts.TestParquetContracts" name="test_schema_consistency" time="0.001"><failure message="AssertionError: Schema validation failed for review_ready_parquet&#10;assert False">self = &lt;tests.contracts.test_parquet_contracts.TestParquetContracts object at 0x106e1bf20&gt;
artifact_paths = {'group_details_parquet': '/path/to/group_details.parquet', 'group_stats_parquet': '/path/to/group_stats.parquet', 'review_ready_parquet': '/path/to/review_ready.parquet'}

    def test_schema_consistency(self, artifact_paths):
        """Test that schemas are consistent across runs."""
        # This test would compare schemas across multiple runs
        # For now, just ensure we can read the schema
        for parquet_type in REQUIRED_COLUMNS:
            if parquet_type in artifact_paths:
                file_path = artifact_paths[parquet_type]
                result = validate_parquet_schema(file_path, parquet_type)
    
&gt;               assert result["valid"], f"Schema validation failed for {parquet_type}"
E               AssertionError: Schema validation failed for review_ready_parquet
E               assert False

tests/contracts/test_parquet_contracts.py:162: AssertionError</failure></testcase><testcase classname="tests.contracts.test_parquet_contracts.TestParquetContracts" name="test_column_types" time="0.001"><failure message="AssertionError: Schema validation failed for review_ready_parquet&#10;assert False">self = &lt;tests.contracts.test_parquet_contracts.TestParquetContracts object at 0x106eb5700&gt;
artifact_paths = {'group_details_parquet': '/path/to/group_details.parquet', 'group_stats_parquet': '/path/to/group_stats.parquet', 'review_ready_parquet': '/path/to/review_ready.parquet'}

    def test_column_types(self, artifact_paths):
        """Test that column types are as expected."""
        expected_types = {
            "group_id": "string",
            "account_name": "string",
            "is_primary": "bool",
            "disposition": "string",
            "group_size": "int64",
            "max_score": "double",
            "primary_name": "string",
            "weakest_edge_to_primary": "double",
        }
    
        for parquet_type in REQUIRED_COLUMNS:
            if parquet_type in artifact_paths:
                file_path = artifact_paths[parquet_type]
                result = validate_parquet_schema(file_path, parquet_type)
    
&gt;               assert result["valid"], f"Schema validation failed for {parquet_type}"
E               AssertionError: Schema validation failed for review_ready_parquet
E               assert False

tests/contracts/test_parquet_contracts.py:183: AssertionError</failure></testcase><testcase classname="tests.contracts.test_parquet_contracts.TestParquetContracts" name="test_no_extra_required_columns" time="0.000"><failure message="AssertionError: Schema validation failed for review_ready_parquet&#10;assert False">self = &lt;tests.contracts.test_parquet_contracts.TestParquetContracts object at 0x106eb4c50&gt;
artifact_paths = {'group_details_parquet': '/path/to/group_details.parquet', 'group_stats_parquet': '/path/to/group_stats.parquet', 'review_ready_parquet': '/path/to/review_ready.parquet'}

    def test_no_extra_required_columns(self, artifact_paths):
        """Test that we don't have unexpected required columns."""
        # This ensures our contract is not too strict
        for parquet_type in REQUIRED_COLUMNS:
            if parquet_type in artifact_paths:
                file_path = artifact_paths[parquet_type]
                result = validate_parquet_schema(file_path, parquet_type)
    
&gt;               assert result["valid"], f"Schema validation failed for {parquet_type}"
E               AssertionError: Schema validation failed for review_ready_parquet
E               assert False

tests/contracts/test_parquet_contracts.py:215: AssertionError</failure></testcase><testcase classname="tests.contracts.test_parquet_contracts.TestParquetContracts" name="test_contract_evolution" time="0.000"><failure message="AssertionError: Schema validation failed for review_ready_parquet&#10;assert False">self = &lt;tests.contracts.test_parquet_contracts.TestParquetContracts object at 0x106eb57c0&gt;
artifact_paths = {'group_details_parquet': '/path/to/group_details.parquet', 'group_stats_parquet': '/path/to/group_stats.parquet', 'review_ready_parquet': '/path/to/review_ready.parquet'}

    def test_contract_evolution(self, artifact_paths):
        """Test that contracts can evolve safely."""
        # This test documents how to safely evolve contracts
        for parquet_type in REQUIRED_COLUMNS:
            if parquet_type in artifact_paths:
                file_path = artifact_paths[parquet_type]
                result = validate_parquet_schema(file_path, parquet_type)
    
&gt;               assert result["valid"], f"Schema validation failed for {parquet_type}"
E               AssertionError: Schema validation failed for review_ready_parquet
E               assert False

tests/contracts/test_parquet_contracts.py:234: AssertionError</failure></testcase><testcase classname="tests.contracts.test_parquet_contracts.TestHardcodedColumnAssumptions" name="test_detect_hardcoded_column_lists" time="0.014" /><testcase classname="tests.contracts.test_parquet_contracts.TestHardcodedColumnAssumptions" name="test_detect_schema_constants_usage" time="0.002"><failure message="Failed: Potential hardcoded column list in /Users/joe.j/Documents/dev/salesforce/apps/company_junction/src/utils/group_details.py:98&#10;Line: return [GROUP_ID, ACCOUNT_NAME, DISPOSITION]&#10;Consider using a schema constant instead.">self = &lt;tests.contracts.test_parquet_contracts.TestHardcodedColumnAssumptions object at 0x106eb5970&gt;

    def test_detect_schema_constants_usage(self):
        """Test that schema constants are used consistently."""
        # Check that DETAILS_COLUMNS and similar constants are defined and used
        src_dir = Path(__file__).parent.parent.parent / "src"
        utils_dir = src_dir / "utils"
    
        schema_files = []
        for py_file in utils_dir.rglob("*.py"):
            try:
                with open(py_file) as f:
                    content = f.read()
    
                # Look for column constant definitions
                if "DETAILS_COLUMNS" in content or "GROUP_STATS_COLUMNS" in content:
                    schema_files.append(py_file)
    
            except Exception:
                continue
    
        # Ensure we have schema constant definitions
        assert len(schema_files) &gt; 0, "No schema constant definitions found in utils/"
    
        # Check that constants are used consistently
        for schema_file in schema_files:
            try:
                with open(schema_file) as f:
                    content = f.read()
    
                # Look for hardcoded column lists that should use constants
                if (
                    "[" in content
                    and "GROUP_ID" in content
                    and "ACCOUNT_NAME" in content
                ):
                    # This is a potential hardcoded list - check if it's in a constant definition
                    lines = content.split("\n")
                    for i, line in enumerate(lines):
                        if (
                            "[" in line
                            and "GROUP_ID" in line
                            and "ACCOUNT_NAME" in line
                        ):
                            # Check if this line defines a constant
                            if "=" in line and (
                                "DETAILS_COLUMNS" in line
                                or "GROUP_STATS_COLUMNS" in line
                            ):
                                continue  # This is a constant definition, which is OK
&gt;                           pytest.fail(
                                f"Potential hardcoded column list in {schema_file}:{i+1}\n"
                                f"Line: {line.strip()}\n"
                                f"Consider using a schema constant instead.",
                            )
E                           Failed: Potential hardcoded column list in /Users/joe.j/Documents/dev/salesforce/apps/company_junction/src/utils/group_details.py:98
E                           Line: return [GROUP_ID, ACCOUNT_NAME, DISPOSITION]
E                           Consider using a schema constant instead.

tests/contracts/test_parquet_contracts.py:343: Failed</failure></testcase><testcase classname="tests.contracts.test_parquet_contracts.TestHardcodedColumnAssumptions" name="test_schema_constants_match_contracts" time="0.000" /><testcase classname="tests.contracts.test_parquet_contracts.TestContractEvolution" name="test_add_optional_column" time="0.000" /><testcase classname="tests.contracts.test_parquet_contracts.TestContractEvolution" name="test_remove_optional_column" time="0.000" /><testcase classname="tests.contracts.test_parquet_contracts.TestContractEvolution" name="test_rename_column_breaking" time="0.000" /><testcase classname="tests.contracts.test_parquet_contracts.TestContractEvolution" name="test_change_column_type_breaking" time="0.000" /><testcase classname="tests.contracts.test_parquet_contracts.TestLegacyColumnHandling" name="test_duckdb_handles_missing_legacy_columns" time="0.012" /><testcase classname="tests.contracts.test_parquet_contracts.TestLegacyColumnHandling" name="test_pyarrow_handles_missing_legacy_columns" time="0.003" /><testcase classname="tests.contracts.test_parquet_contracts.TestLegacyColumnHandling" name="test_duckdb_handles_present_legacy_columns" time="0.006"><failure message="AssertionError: assert 2 == 3&#10; +  where 2 = len([('group1', 'acc1', 'Company A', 'INC', '2023-01-01', 'Keep', ...), ('group2', 'acc2', 'Company B', 'LLC', '2023-01-02', 'Update', ...)])">self = &lt;tests.contracts.test_parquet_contracts.TestLegacyColumnHandling object at 0x106eb6450&gt;
sample_data_with_legacy_columns = pyarrow.Table
group_id: string
account_id: string
account_name: string
suffix_class: string
created_date: string
dispo...
disposition: [["Keep","Update","Delete"]]
is_primary: [[true,false,false]]
weakest_edge_to_primary: [[0.95,0.85,0.75]]

    def test_duckdb_handles_present_legacy_columns(
        self,
        sample_data_with_legacy_columns,
    ):
        """Test that DuckDB backend works with present legacy columns."""
        with tempfile.NamedTemporaryFile(suffix=".parquet", delete=False) as tmp_file:
            pq.write_table(sample_data_with_legacy_columns, tmp_file.name)
    
            try:
                import duckdb
    
                conn = duckdb.connect()
    
                # Test filtering by min_edge_strength (should work with legacy columns)
                result = conn.execute(
                    f"""
                    SELECT * FROM read_parquet('{tmp_file.name}')
                    WHERE weakest_edge_to_primary &gt;= 0.8
                """,
                ).fetchall()
&gt;               assert len(result) == 3
E               AssertionError: assert 2 == 3
E                +  where 2 = len([('group1', 'acc1', 'Company A', 'INC', '2023-01-01', 'Keep', ...), ('group2', 'acc2', 'Company B', 'LLC', '2023-01-02', 'Update', ...)])

tests/contracts/test_parquet_contracts.py:526: AssertionError</failure></testcase><testcase classname="tests.contracts.test_parquet_contracts.TestLegacyColumnHandling" name="test_pyarrow_handles_present_legacy_columns" time="0.003"><failure message="assert 2 == 3&#10; +  where 2 = pyarrow.Table\ngroup_id: string\naccount_id: string\naccount_name: string\nsuffix_class: string\ncreated_date: string\ndispo...1-01&quot;,&quot;2023-01-02&quot;]]\ndisposition: [[&quot;Keep&quot;,&quot;Update&quot;]]\nis_primary: [[true,false]]\nweakest_edge_to_primary: [[0.95,0.85]].num_rows">self = &lt;tests.contracts.test_parquet_contracts.TestLegacyColumnHandling object at 0x106eb6630&gt;
sample_data_with_legacy_columns = pyarrow.Table
group_id: string
account_id: string
account_name: string
suffix_class: string
created_date: string
dispo...
disposition: [["Keep","Update","Delete"]]
is_primary: [[true,false,false]]
weakest_edge_to_primary: [[0.95,0.85,0.75]]

    def test_pyarrow_handles_present_legacy_columns(
        self,
        sample_data_with_legacy_columns,
    ):
        """Test that PyArrow backend works with present legacy columns."""
        with tempfile.NamedTemporaryFile(suffix=".parquet", delete=False) as tmp_file:
            pq.write_table(sample_data_with_legacy_columns, tmp_file.name)
    
            try:
                table = pq.read_table(tmp_file.name)
                assert table.num_rows == 3
    
                # Test filtering by min_edge_strength (should work with legacy columns)
                filtered = table.filter(
                    pa.compute.greater_equal(
                        table["weakest_edge_to_primary"],
                        pa.scalar(0.8),
                    ),
                )
&gt;               assert filtered.num_rows == 3
E               assert 2 == 3
E                +  where 2 = pyarrow.Table\ngroup_id: string\naccount_id: string\naccount_name: string\nsuffix_class: string\ncreated_date: string\ndispo...1-01","2023-01-02"]]\ndisposition: [["Keep","Update"]]\nis_primary: [[true,false]]\nweakest_edge_to_primary: [[0.95,0.85]].num_rows

tests/contracts/test_parquet_contracts.py:561: AssertionError</failure></testcase><testcase classname="tests.contracts.test_parquet_contracts.TestLegacyColumnHandling" name="test_conditional_filtering_skips_missing_columns" time="0.002" /><testcase classname="tests.contracts.test_parquet_contracts.TestLegacyColumnHandling" name="test_conditional_filtering_works_with_present_columns" time="0.002"><failure message="TypeError: Got unexpected argument type &lt;class 'pyarrow._compute.Expression'&gt; for compute function">self = &lt;tests.contracts.test_parquet_contracts.TestLegacyColumnHandling object at 0x106eb67b0&gt;
sample_data_with_legacy_columns = pyarrow.Table
group_id: string
account_id: string
account_name: string
suffix_class: string
created_date: string
dispo...
disposition: [["Keep","Update","Delete"]]
is_primary: [[true,false,false]]
weakest_edge_to_primary: [[0.95,0.85,0.75]]

    def test_conditional_filtering_works_with_present_columns(
        self,
        sample_data_with_legacy_columns,
    ):
        """Test that conditional filtering works when columns are present."""
        with tempfile.NamedTemporaryFile(suffix=".parquet", delete=False) as tmp_file:
            pq.write_table(sample_data_with_legacy_columns, tmp_file.name)
    
            try:
                # Test the conditional filtering logic
                from src.utils.filtering import apply_filters_pyarrow
    
                # Get available columns
                table = pq.read_table(tmp_file.name)
                available_columns = table.column_names
    
                # Test filtering with min_edge_strength (should work with legacy columns)
                filters = {"min_edge_strength": 0.8}
&gt;               filtered = apply_filters_pyarrow(table, filters, available_columns)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/contracts/test_parquet_contracts.py:616: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/utils/filtering.py:157: in apply_filters_pyarrow
    es_mask = pc.greater_equal(
/Users/joe.j/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pyarrow/compute.py:252: in wrapper
    return func.call(args, None, memory_pool)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pyarrow/_compute.pyx:386: in pyarrow._compute.Function.call
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

&gt;   ???
E   TypeError: Got unexpected argument type &lt;class 'pyarrow._compute.Expression'&gt; for compute function

pyarrow/_compute.pyx:519: TypeError</failure></testcase><testcase classname="tests.lints.test_no_schema_fragile_hardcoding.TestNoSchemaFragileHardcoding" name="test_no_hardcoded_primary_name_in_details_context" time="0.058"><failure message="Failed: Found 2 hardcoded primary_name references in details context:&#10;app/components/group_details.py:67 - primary_name,&#10;app/components/group_details.py:79 - primary_name,&#10;&#10;Use get_order_by(sort_key, context='group_details') or build_sort_expression(sort_key, context='group_details') instead.">self = &lt;tests.lints.test_no_schema_fragile_hardcoding.TestNoSchemaFragileHardcoding object at 0x106eb6b70&gt;

    def test_no_hardcoded_primary_name_in_details_context(self):
        """Test that group_details context doesn't use hardcoded primary_name."""
        project_root = Path(__file__).parent.parent.parent
        details_files = [
            project_root / "src" / "utils" / "group_details.py",
            project_root / "app" / "components" / "group_details.py",
        ]
    
        violations = []
    
        for file_path in details_files:
            if not file_path.exists():
                continue
    
            references = self.find_fragile_references(file_path)
            for line_num, line_content in references:
                # Check for hardcoded primary_name usage that should use context-aware functions
                if (
                    "primary_name" in line_content.lower()
                    and "context" not in line_content
                ):
                    violations.append(
                        f"{file_path.relative_to(project_root)}:{line_num} - {line_content}",
                    )
    
        if violations:
&gt;           pytest.fail(
                f"Found {len(violations)} hardcoded primary_name references in details context:\n"
                + "\n".join(violations)
                + "\n\nUse get_order_by(sort_key, context='group_details') or build_sort_expression(sort_key, context='group_details') instead.",
            )
E           Failed: Found 2 hardcoded primary_name references in details context:
E           app/components/group_details.py:67 - primary_name,
E           app/components/group_details.py:79 - primary_name,
E           
E           Use get_order_by(sort_key, context='group_details') or build_sort_expression(sort_key, context='group_details') instead.

tests/lints/test_no_schema_fragile_hardcoding.py:164: Failed</failure></testcase><testcase classname="tests.lints.test_no_schema_fragile_hardcoding.TestNoSchemaFragileHardcoding" name="test_no_hardcoded_weakest_edge_without_availability_check" time="0.215"><failure message="Failed: Found 10 WEAKEST_EDGE_TO_PRIMARY references without availability checks:&#10;src/utils/filtering.py:17 - WEAKEST_EDGE_TO_PRIMARY,&#10;src/utils/filtering.py:158 - table[WEAKEST_EDGE_TO_PRIMARY],&#10;src/utils/group_details.py:43 - WEAKEST_EDGE_TO_PRIMARY,&#10;src/utils/group_details.py:125 - where_sql.append(WEAKEST_EDGE_TO_PRIMARY + &quot; &gt;= ?&quot;)&#10;src/utils/group_pagination.py:28 - WEAKEST_EDGE_TO_PRIMARY,&#10;src/utils/group_pagination.py:603 - WEAKEST_EDGE_TO_PRIMARY,&#10;src/utils/group_pagination.py:614 - stats_select += f&quot;, MAX({WEAKEST_EDGE_TO_PRIMARY}) AS {MAX_SCORE}&quot;&#10;app/components/group_details.py:19 - WEAKEST_EDGE_TO_PRIMARY,&#10;app/components/group_details.py:280 - WEAKEST_EDGE_TO_PRIMARY,&#10;app/components/group_details.py:330 - WEAKEST_EDGE_TO_PRIMARY: st.column_config.NumberColumn(&#10;&#10;Use conditional filtering with available_columns or context-aware functions.">self = &lt;tests.lints.test_no_schema_fragile_hardcoding.TestNoSchemaFragileHardcoding object at 0x106eb6d20&gt;

    def test_no_hardcoded_weakest_edge_without_availability_check(self):
        """Test that WEAKEST_EDGE_TO_PRIMARY is not used without availability checks."""
        project_root = Path(__file__).parent.parent.parent
        search_dirs = ["src/utils", "app/components"]
    
        violations = []
    
        for dir_name in search_dirs:
            dir_path = project_root / dir_name
            if not dir_path.exists():
                continue
    
            for file_path in dir_path.rglob("*.py"):
                if self.should_exclude_file(file_path):
                    continue
    
                references = self.find_fragile_references(file_path)
                for line_num, line_content in references:
                    # Check for WEAKEST_EDGE_TO_PRIMARY usage without availability checks
                    if "WEAKEST_EDGE_TO_PRIMARY" in line_content:
                        if not any(
                            pattern in line_content
                            for pattern in [
                                "available_columns",
                                "in.*available_columns",
                                "is.*None.*or",
                                "context=",
                                "get_order_by",
                                "build_sort_expression",
                                "_build_where_clause",
                                "apply_filters_pyarrow",
                            ]
                        ):
                            violations.append(
                                f"{file_path.relative_to(project_root)}:{line_num} - {line_content}",
                            )
    
        if violations:
&gt;           pytest.fail(
                f"Found {len(violations)} WEAKEST_EDGE_TO_PRIMARY references without availability checks:\n"
                + "\n".join(violations)
                + "\n\nUse conditional filtering with available_columns or context-aware functions.",
            )
E           Failed: Found 10 WEAKEST_EDGE_TO_PRIMARY references without availability checks:
E           src/utils/filtering.py:17 - WEAKEST_EDGE_TO_PRIMARY,
E           src/utils/filtering.py:158 - table[WEAKEST_EDGE_TO_PRIMARY],
E           src/utils/group_details.py:43 - WEAKEST_EDGE_TO_PRIMARY,
E           src/utils/group_details.py:125 - where_sql.append(WEAKEST_EDGE_TO_PRIMARY + " &gt;= ?")
E           src/utils/group_pagination.py:28 - WEAKEST_EDGE_TO_PRIMARY,
E           src/utils/group_pagination.py:603 - WEAKEST_EDGE_TO_PRIMARY,
E           src/utils/group_pagination.py:614 - stats_select += f", MAX({WEAKEST_EDGE_TO_PRIMARY}) AS {MAX_SCORE}"
E           app/components/group_details.py:19 - WEAKEST_EDGE_TO_PRIMARY,
E           app/components/group_details.py:280 - WEAKEST_EDGE_TO_PRIMARY,
E           app/components/group_details.py:330 - WEAKEST_EDGE_TO_PRIMARY: st.column_config.NumberColumn(
E           
E           Use conditional filtering with available_columns or context-aware functions.

tests/lints/test_no_schema_fragile_hardcoding.py:208: Failed</failure></testcase><testcase classname="tests.lints.test_no_schema_fragile_hardcoding.TestNoSchemaFragileHardcoding" name="test_no_hardcoded_is_primary_without_availability_check" time="0.218"><failure message="Failed: Found 7 IS_PRIMARY references without availability checks:&#10;src/utils/group_details.py:41 - IS_PRIMARY,&#10;src/utils/group_pagination.py:25 - IS_PRIMARY,&#10;src/utils/group_pagination.py:602 - IS_PRIMARY,&#10;src/utils/group_pagination.py:620 - primary_name_select = f&quot;any_value({ACCOUNT_NAME}) FILTER (WHERE {IS_PRIMARY}) AS {PRIMARY_NAME}&quot;&#10;app/components/group_details.py:17 - IS_PRIMARY,&#10;app/components/group_details.py:279 - IS_PRIMARY,&#10;app/components/group_details.py:326 - IS_PRIMARY: st.column_config.CheckboxColumn(&#10;&#10;Use conditional filtering with available_columns or context-aware functions.">self = &lt;tests.lints.test_no_schema_fragile_hardcoding.TestNoSchemaFragileHardcoding object at 0x106eb6ea0&gt;

    def test_no_hardcoded_is_primary_without_availability_check(self):
        """Test that IS_PRIMARY is not used without availability checks."""
        project_root = Path(__file__).parent.parent.parent
        search_dirs = ["src/utils", "app/components"]
    
        violations = []
    
        for dir_name in search_dirs:
            dir_path = project_root / dir_name
            if not dir_path.exists():
                continue
    
            for file_path in dir_path.rglob("*.py"):
                if self.should_exclude_file(file_path):
                    continue
    
                references = self.find_fragile_references(file_path)
                for line_num, line_content in references:
                    # Check for IS_PRIMARY usage without availability checks
                    if "IS_PRIMARY" in line_content:
                        if not any(
                            pattern in line_content
                            for pattern in [
                                "available_columns",
                                "in.*available_columns",
                                r"in.*group_data\.columns",
                                "context=",
                                "get_order_by",
                                "build_sort_expression",
                                "_build_where_clause",
                                "apply_filters_pyarrow",
                                r"\.get\(",
                                "if.*IS_PRIMARY.*in",
                            ]
                        ):
                            violations.append(
                                f"{file_path.relative_to(project_root)}:{line_num} - {line_content}",
                            )
    
        if violations:
&gt;           pytest.fail(
                f"Found {len(violations)} IS_PRIMARY references without availability checks:\n"
                + "\n".join(violations)
                + "\n\nUse conditional filtering with available_columns or context-aware functions.",
            )
E           Failed: Found 7 IS_PRIMARY references without availability checks:
E           src/utils/group_details.py:41 - IS_PRIMARY,
E           src/utils/group_pagination.py:25 - IS_PRIMARY,
E           src/utils/group_pagination.py:602 - IS_PRIMARY,
E           src/utils/group_pagination.py:620 - primary_name_select = f"any_value({ACCOUNT_NAME}) FILTER (WHERE {IS_PRIMARY}) AS {PRIMARY_NAME}"
E           app/components/group_details.py:17 - IS_PRIMARY,
E           app/components/group_details.py:279 - IS_PRIMARY,
E           app/components/group_details.py:326 - IS_PRIMARY: st.column_config.CheckboxColumn(
E           
E           Use conditional filtering with available_columns or context-aware functions.

tests/lints/test_no_schema_fragile_hardcoding.py:254: Failed</failure></testcase><testcase classname="tests.lints.test_no_schema_fragile_hardcoding.TestNoSchemaFragileHardcoding" name="test_context_aware_functions_used_correctly" time="0.000" /><testcase classname="tests.lints.test_no_ui_helpers_import" name="test_no_ui_helpers_import" time="0.037" /><testcase classname="tests.lints.test_no_ui_helpers_import" name="test_ui_helpers_deprecation_warning" time="0.002" /><testcase classname="tests.lints.test_no_ui_helpers_import" name="test_ui_helpers_functions_still_work" time="0.000" /><testcase classname="tests.lints.test_no_ui_helpers_import" name="test_ui_helpers_file_is_gone" time="0.000" /><testcase classname="tests.perf.test_groups_bench.TestGroupsPageBenchmarks" name="test_groups_page_10k_pyarrow" time="0.001"><error message="failed on setup with &quot;file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 218&#10;      @pytest.mark.performance&#10;      def test_groups_page_10k_pyarrow(self, benchmark, synthetic_10k_paths, monkeypatch):&#10;E       fixture 'benchmark' not found&#10;&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory&#10;&gt;       use 'pytest --fixtures [testpath]' for help on them.&#10;&#10;/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:218&quot;">file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 218
      @pytest.mark.performance
      def test_groups_page_10k_pyarrow(self, benchmark, synthetic_10k_paths, monkeypatch):
E       fixture 'benchmark' not found
&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
&gt;       use 'pytest --fixtures [testpath]' for help on them.

/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:218</error></testcase><testcase classname="tests.perf.test_groups_bench.TestGroupsPageBenchmarks" name="test_groups_page_10k_duckdb" time="0.000"><error message="failed on setup with &quot;file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 245&#10;      @pytest.mark.performance&#10;      def test_groups_page_10k_duckdb(self, benchmark, synthetic_10k_paths, monkeypatch):&#10;E       fixture 'benchmark' not found&#10;&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory&#10;&gt;       use 'pytest --fixtures [testpath]' for help on them.&#10;&#10;/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:245&quot;">file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 245
      @pytest.mark.performance
      def test_groups_page_10k_duckdb(self, benchmark, synthetic_10k_paths, monkeypatch):
E       fixture 'benchmark' not found
&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
&gt;       use 'pytest --fixtures [testpath]' for help on them.

/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:245</error></testcase><testcase classname="tests.perf.test_groups_bench.TestGroupsPageBenchmarks" name="test_groups_page_100k_pyarrow" time="0.000"><error message="failed on setup with &quot;file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 273&#10;      @pytest.mark.performance&#10;      def test_groups_page_100k_pyarrow(&#10;E       fixture 'benchmark' not found&#10;&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory&#10;&gt;       use 'pytest --fixtures [testpath]' for help on them.&#10;&#10;/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:273&quot;">file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 273
      @pytest.mark.performance
      def test_groups_page_100k_pyarrow(
E       fixture 'benchmark' not found
&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
&gt;       use 'pytest --fixtures [testpath]' for help on them.

/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:273</error></testcase><testcase classname="tests.perf.test_groups_bench.TestGroupsPageBenchmarks" name="test_groups_page_100k_duckdb" time="0.000"><error message="failed on setup with &quot;file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 305&#10;      @pytest.mark.performance&#10;      def test_groups_page_100k_duckdb(&#10;E       fixture 'benchmark' not found&#10;&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory&#10;&gt;       use 'pytest --fixtures [testpath]' for help on them.&#10;&#10;/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:305&quot;">file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 305
      @pytest.mark.performance
      def test_groups_page_100k_duckdb(
E       fixture 'benchmark' not found
&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
&gt;       use 'pytest --fixtures [testpath]' for help on them.

/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:305</error></testcase><testcase classname="tests.perf.test_groups_bench.TestGroupsPageBenchmarks" name="test_groups_page_1m_pyarrow" time="0.000"><error message="failed on setup with &quot;file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 337&#10;      @pytest.mark.performance&#10;      @pytest.mark.slow&#10;      def test_groups_page_1m_pyarrow(self, benchmark, synthetic_1m_paths, monkeypatch):&#10;E       fixture 'benchmark' not found&#10;&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory&#10;&gt;       use 'pytest --fixtures [testpath]' for help on them.&#10;&#10;/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:337&quot;">file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 337
      @pytest.mark.performance
      @pytest.mark.slow
      def test_groups_page_1m_pyarrow(self, benchmark, synthetic_1m_paths, monkeypatch):
E       fixture 'benchmark' not found
&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
&gt;       use 'pytest --fixtures [testpath]' for help on them.

/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:337</error></testcase><testcase classname="tests.perf.test_groups_bench.TestGroupsPageBenchmarks" name="test_groups_page_1m_duckdb" time="0.000"><error message="failed on setup with &quot;file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 365&#10;      @pytest.mark.performance&#10;      @pytest.mark.slow&#10;      def test_groups_page_1m_duckdb(self, benchmark, synthetic_1m_paths, monkeypatch):&#10;E       fixture 'benchmark' not found&#10;&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory&#10;&gt;       use 'pytest --fixtures [testpath]' for help on them.&#10;&#10;/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:365&quot;">file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 365
      @pytest.mark.performance
      @pytest.mark.slow
      def test_groups_page_1m_duckdb(self, benchmark, synthetic_1m_paths, monkeypatch):
E       fixture 'benchmark' not found
&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
&gt;       use 'pytest --fixtures [testpath]' for help on them.

/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:365</error></testcase><testcase classname="tests.perf.test_groups_bench.TestGroupDetailsBenchmarks" name="test_group_details_10k_pyarrow" time="0.003"><error message="failed on setup with &quot;file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 397&#10;      @pytest.mark.performance&#10;      def test_group_details_10k_pyarrow(&#10;E       fixture 'benchmark' not found&#10;&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory&#10;&gt;       use 'pytest --fixtures [testpath]' for help on them.&#10;&#10;/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:397&quot;">file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 397
      @pytest.mark.performance
      def test_group_details_10k_pyarrow(
E       fixture 'benchmark' not found
&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
&gt;       use 'pytest --fixtures [testpath]' for help on them.

/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:397</error></testcase><testcase classname="tests.perf.test_groups_bench.TestGroupDetailsBenchmarks" name="test_group_details_10k_duckdb" time="0.000"><error message="failed on setup with &quot;file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 430&#10;      @pytest.mark.performance&#10;      def test_group_details_10k_duckdb(&#10;E       fixture 'benchmark' not found&#10;&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory&#10;&gt;       use 'pytest --fixtures [testpath]' for help on them.&#10;&#10;/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:430&quot;">file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 430
      @pytest.mark.performance
      def test_group_details_10k_duckdb(
E       fixture 'benchmark' not found
&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
&gt;       use 'pytest --fixtures [testpath]' for help on them.

/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:430</error></testcase><testcase classname="tests.perf.test_groups_bench.TestSortVariants" name="test_sort_variants_10k" time="0.000"><error message="failed on setup with &quot;file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 467&#10;      @pytest.mark.performance&#10;      def test_sort_variants_10k(self, benchmark, synthetic_10k_paths, monkeypatch):&#10;E       fixture 'benchmark' not found&#10;&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory&#10;&gt;       use 'pytest --fixtures [testpath]' for help on them.&#10;&#10;/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:467&quot;">file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 467
      @pytest.mark.performance
      def test_sort_variants_10k(self, benchmark, synthetic_10k_paths, monkeypatch):
E       fixture 'benchmark' not found
&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
&gt;       use 'pytest --fixtures [testpath]' for help on them.

/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:467</error></testcase><testcase classname="tests.perf.test_groups_bench.TestFilterVariants" name="test_filter_variants_10k" time="0.000"><error message="failed on setup with &quot;file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 503&#10;      @pytest.mark.performance&#10;      def test_filter_variants_10k(self, benchmark, synthetic_10k_paths, monkeypatch):&#10;E       fixture 'benchmark' not found&#10;&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory&#10;&gt;       use 'pytest --fixtures [testpath]' for help on them.&#10;&#10;/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:503&quot;">file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py, line 503
      @pytest.mark.performance
      def test_filter_variants_10k(self, benchmark, synthetic_10k_paths, monkeypatch):
E       fixture 'benchmark' not found
&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, synthetic_100k_data, synthetic_100k_paths, synthetic_10k_data, synthetic_10k_paths, synthetic_1m_data, synthetic_1m_paths, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
&gt;       use 'pytest --fixtures [testpath]' for help on them.

/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/perf/test_groups_bench.py:503</error></testcase><testcase classname="tests.test_alias_equivalence" name="test_alias_equivalence_optimized_vs_legacy" time="0.015" /><testcase classname="tests.test_alias_equivalence" name="test_alias_equivalence_edge_cases" time="0.004" /><testcase classname="tests.test_alias_equivalence" name="test_alias_equivalence_mismatched_sources" time="0.006" /><testcase classname="tests.test_alias_equivalence" name="test_alias_equivalence_sequential_fallback" time="0.004" /><testcase classname="tests.test_alias_matching.TestAliasMatching" name="test_compute_alias_matches" time="0.004" /><testcase classname="tests.test_alias_matching_parallelism.TestAliasMatchingParallelism" name="test_parallel_executor_integration" time="0.005"><failure message="AssertionError: Expected 'should_use_parallel' to have been called once. Called 2 times.&#10;Calls: [call(5), call(5)].&#10;&#10;pytest introspection follows:&#10;&#10;Args:&#10;assert (5,) == ()&#10;  &#10;  Left contains one more item: 5&#10;  Use -v to get more diff">self = &lt;Mock name='mock.should_use_parallel' id='4840473712'&gt;

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
&gt;           raise AssertionError(msg)
E           AssertionError: Expected 'should_use_parallel' to have been called once. Called 2 times.
E           Calls: [call(5), call(5)].

/Users/joe.j/.pyenv/versions/3.12.2/lib/python3.12/unittest/mock.py:923: AssertionError

During handling of the above exception, another exception occurred:

self = &lt;tests.test_alias_matching_parallelism.TestAliasMatchingParallelism object at 0x120348920&gt;

    def test_parallel_executor_integration(self):
        """Test that ParallelExecutor is properly integrated."""
        # Create a mock ParallelExecutor
        mock_executor = Mock(spec=ParallelExecutor)
        mock_executor.should_use_parallel.side_effect = lambda x: True
        mock_executor.workers = 2
        mock_executor.execute_chunked.return_value = [
            [
                {
                    "record_id": 100,
                    "alias_text": "Acme Corp",
                    "match_record_id": 101,
                    "match_group_id": "G1",
                    "score": 95,
                    "suffix_match": True,
                },
            ],
            [
                {
                    "record_id": 101,
                    "alias_text": "Acme Corp",
                    "match_record_id": 100,
                    "match_group_id": "G1",
                    "score": 95,
                    "suffix_match": True,
                },
            ],
        ]
    
        # Call compute_alias_matches with ParallelExecutor
        result_df, stats = compute_alias_matches(
            self.df_norm,
            self.df_groups,
            self.settings,
            parallel_executor=mock_executor,
        )
    
        # Verify ParallelExecutor was used
&gt;       mock_executor.should_use_parallel.assert_called_once()
E       AssertionError: Expected 'should_use_parallel' to have been called once. Called 2 times.
E       Calls: [call(5), call(5)].
E       
E       pytest introspection follows:
E       
E       Args:
E       assert (5,) == ()
E         
E         Left contains one more item: 5
E         Use -v to get more diff

tests/test_alias_matching_parallelism.py:107: AssertionError</failure></testcase><testcase classname="tests.test_alias_matching_parallelism.TestAliasMatchingParallelism" name="test_sequential_fallback_when_parallel_disabled" time="0.004" /><testcase classname="tests.test_alias_matching_parallelism.TestAliasMatchingParallelism" name="test_no_parallel_executor_fallback" time="0.005" /><testcase classname="tests.test_alias_matching_parallelism.TestAliasMatchingParallelism" name="test_first_token_bucket_consistency" time="0.001" /><testcase classname="tests.test_alias_matching_parallelism.TestAliasMatchingParallelism" name="test_process_one_record_optimized" time="0.001" /><testcase classname="tests.test_alias_matching_parallelism.TestAliasMatchingParallelism" name="test_parallel_executor_chunking_consistency" time="0.004" /><testcase classname="tests.test_alias_matching_parallelism.TestAliasMatchingParallelism" name="test_settings_integration" time="0.006" /><testcase classname="tests.test_alias_matching_parallelism.TestAliasMatchingParallelism" name="test_error_handling_in_parallel_execution" time="0.004" /><testcase classname="tests.test_alias_matching_parallelism.TestAliasMatchingParallelism" name="test_deterministic_output_ordering" time="0.006" /><testcase classname="tests.test_alias_progress_logger" name="test_progress_logging_appears" time="0.007" /><testcase classname="tests.test_alias_progress_logger" name="test_progress_logging_rate_limited" time="0.004" /><testcase classname="tests.test_alias_progress_logger" name="test_progress_logging_disabled_when_sequential" time="0.005" /><testcase classname="tests.test_alias_progress_logger" name="test_progress_logging_disabled_when_optimize_false" time="0.005" /><testcase classname="tests.test_alias_validation" name="test_alias_equivalence_on_fixture" time="0.009" /><testcase classname="tests.test_alias_validation" name="test_alias_determinism_on_fixture" time="0.009" /><testcase classname="tests.test_alias_validation" name="test_edge_case_mismatched_sources" time="0.003" /><testcase classname="tests.test_alias_validation" name="test_large_bucket_warning[fast]" time="0.000"><skipped type="pytest.skip" message="TODO: Phase 1.26.1 - Temporarily skipped for QA efficiency, will re-enable after Phase 1.25.1">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_alias_validation.py:182: TODO: Phase 1.26.1 - Temporarily skipped for QA efficiency, will re-enable after Phase 1.25.1</skipped></testcase><testcase classname="tests.test_alias_validation" name="test_large_bucket_warning[slow]" time="0.000"><skipped type="pytest.skip" message="TODO: Phase 1.26.1 - Temporarily skipped for QA efficiency, will re-enable after Phase 1.25.1">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_alias_validation.py:182: TODO: Phase 1.26.1 - Temporarily skipped for QA efficiency, will re-enable after Phase 1.25.1</skipped></testcase><testcase classname="tests.test_brand_suggestions.TestBrandSuggestions" name="test_generate_brand_suggestions_basic" time="0.001" /><testcase classname="tests.test_brand_suggestions.TestBrandSuggestions" name="test_generate_brand_suggestions_exclude_configured_tokens" time="0.000" /><testcase classname="tests.test_brand_suggestions.TestBrandSuggestions" name="test_generate_brand_suggestions_minimum_criteria" time="0.000" /><testcase classname="tests.test_brand_suggestions.TestBrandSuggestions" name="test_generate_brand_suggestions_empty_inputs" time="0.001" /><testcase classname="tests.test_brand_suggestions.TestBrandSuggestions" name="test_generate_brand_suggestions_confidence_calculation" time="0.000" /><testcase classname="tests.test_cache_keys.TestFingerprint" name="test_fingerprint_missing_file" time="0.000" /><testcase classname="tests.test_cache_keys.TestFingerprint" name="test_fingerprint_existing_file" time="0.001" /><testcase classname="tests.test_cache_keys.TestFingerprint" name="test_fingerprint_os_error" time="0.000" /><testcase classname="tests.test_cache_keys.TestCacheKey" name="test_cache_key_creation" time="0.000" /><testcase classname="tests.test_cache_keys.TestCacheKey" name="test_cache_key_compute" time="0.000" /><testcase classname="tests.test_cache_keys.TestCacheKey" name="test_cache_key_validate_valid" time="0.000" /><testcase classname="tests.test_cache_keys.TestCacheKey" name="test_cache_key_validate_invalid" time="0.000" /><testcase classname="tests.test_cache_keys.TestBuildCacheKey" name="test_build_cache_key_basic" time="0.001" /><testcase classname="tests.test_cache_keys.TestBuildCacheKey" name="test_build_cache_key_with_filters" time="0.000" /><testcase classname="tests.test_cache_keys.TestBuildCacheKey" name="test_build_cache_key_parity" time="0.001" /><testcase classname="tests.test_cache_keys.TestBuildDetailsCacheKey" name="test_build_details_cache_key_basic" time="0.000" /><testcase classname="tests.test_cache_keys" name="test_in_clause_helper" time="0.000" /><testcase classname="tests.test_cache_keys" name="test_settings_defaults_parity" time="0.002" /><testcase classname="tests.test_cache_keys" name="test_deterministic_pagination" time="0.031" /><testcase classname="tests.test_cache_keys" name="test_logger_identity_parity" time="0.000" /><testcase classname="tests.test_cache_keys" name="test_stats_path_no_aliasing" time="0.001" /><testcase classname="tests.test_cache_keys" name="test_stats_path_with_filters" time="0.005" /><testcase classname="tests.test_cache_keys" name="test_pyarrow_details_group_id_filtering" time="0.008" /><testcase classname="tests.test_cache_keys" name="test_config_validation_edge_cases" time="0.000" /><testcase classname="tests.test_cache_keys" name="test_force_backend_flags" time="0.002" /><testcase classname="tests.test_cache_keys" name="test_force_backend_flags_precedence" time="0.001" /><testcase classname="tests.test_cache_keys" name="test_force_backend_flags_precedence_details" time="0.001" /><testcase classname="tests.test_cache_keys" name="test_pyarrow_projection_safety" time="0.002" /><testcase classname="tests.test_cache_keys" name="test_stats_path_threads_cap" time="0.001" /><testcase classname="tests.test_cache_utils" name="test_latest_pointer_operations" time="0.000"><error message="failed on setup with &quot;file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py, line 154&#10;  def test_latest_pointer_operations(sample_runs, cache_utils_workspace):&#10;file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py, line 22&#10;  @pytest.fixture&#10;  def sample_runs(cache_utils_workspace):&#10;E       fixture 'cache_utils_workspace' not found&#10;&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, failed_runs, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_runs, session_mocker, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory&#10;&gt;       use 'pytest --fixtures [testpath]' for help on them.&#10;&#10;/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py:22&quot;">file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py, line 154
  def test_latest_pointer_operations(sample_runs, cache_utils_workspace):
file /Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py, line 22
  @pytest.fixture
  def sample_runs(cache_utils_workspace):
E       fixture 'cache_utils_workspace' not found
&gt;       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, cov, doctest_namespace, failed_runs, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_runs, session_mocker, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
&gt;       use 'pytest --fixtures [testpath]' for help on them.

/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py:22</error></testcase><testcase classname="tests.test_cache_utils" name="test_prune_old_runs" time="0.000"><skipped type="pytest.skip" message="TODO: Phase 1.26.1 - Update cache utils tests for new path utilities">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py:176: TODO: Phase 1.26.1 - Update cache utils tests for new path utilities</skipped></testcase><testcase classname="tests.test_cache_utils" name="test_cleanup_failed_runs" time="0.000"><skipped type="pytest.skip" message="TODO: Phase 1.26.1 - Update cache utils tests for new path utilities">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py:198: TODO: Phase 1.26.1 - Update cache utils tests for new path utilities</skipped></testcase><testcase classname="tests.test_cache_utils" name="test_preview_delete_runs" time="0.000"><skipped type="pytest.skip" message="TODO: Phase 1.26.1 - Update cache utils tests for new path utilities">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py:220: TODO: Phase 1.26.1 - Update cache utils tests for new path utilities</skipped></testcase><testcase classname="tests.test_cache_utils" name="test_delete_runs" time="0.000"><skipped type="pytest.skip" message="TODO: Phase 1.26.1 - Update cache utils tests for new path utilities">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py:240: TODO: Phase 1.26.1 - Update cache utils tests for new path utilities</skipped></testcase><testcase classname="tests.test_cache_utils" name="test_recompute_latest_pointer" time="0.000"><skipped type="pytest.skip" message="TODO: Phase 1.26.1 - Update cache utils tests for new path utilities">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py:264: TODO: Phase 1.26.1 - Update cache utils tests for new path utilities</skipped></testcase><testcase classname="tests.test_cache_utils" name="test_remove_latest_pointer" time="0.000"><skipped type="pytest.skip" message="TODO: Phase 1.26.1 - Update cache utils tests for new path utilities">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py:287: TODO: Phase 1.26.1 - Update cache utils tests for new path utilities</skipped></testcase><testcase classname="tests.test_cache_utils" name="test_get_next_latest_run" time="0.000"><skipped type="pytest.skip" message="TODO: Phase 1.26.1 - Update cache utils tests for new path utilities">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py:308: TODO: Phase 1.26.1 - Update cache utils tests for new path utilities</skipped></testcase><testcase classname="tests.test_cache_utils" name="test_recompute_latest_pointer_empty" time="0.000"><skipped type="pytest.skip" message="TODO: Phase 1.26.1 - Update cache utils tests for new path utilities">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py:329: TODO: Phase 1.26.1 - Update cache utils tests for new path utilities</skipped></testcase><testcase classname="tests.test_cache_utils" name="test_delete_runs_with_stuck_running_status" time="0.000"><skipped type="pytest.skip" message="TODO: Phase 1.26.1 - Update cache utils tests for new path utilities">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py:342: TODO: Phase 1.26.1 - Update cache utils tests for new path utilities</skipped></testcase><testcase classname="tests.test_cache_utils" name="test_delete_all_runs_scenarios" time="0.000"><skipped type="pytest.skip" message="TODO: Phase 1.26.1 - Update cache utils tests for new path utilities">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_cache_utils.py:369: TODO: Phase 1.26.1 - Update cache utils tests for new path utilities</skipped></testcase><testcase classname="tests.test_changelog_dates" name="test_changelog_date_format" time="0.005" /><testcase classname="tests.test_changelog_dates" name="test_changelog_date_consistency" time="0.002" /><testcase classname="tests.test_changelog_dates" name="test_phase_number_format" time="0.002" /><testcase classname="tests.test_cleaning.TestCleaning" name="test_enhanced_filtering_removes_problematic_records" time="0.036" /><testcase classname="tests.test_cleaning.TestCleaning" name="test_invalid_file_format" time="0.001" /><testcase classname="tests.test_cleaning.TestCleaning" name="test_load_salesforce_data_csv" time="0.005" /><testcase classname="tests.test_cleaning.TestCleaning" name="test_performance_logging_context_manager" time="0.012" /><testcase classname="tests.test_cleaning.TestCleaning" name="test_validate_required_columns" time="0.001"><failure message="ValueError: Missing required name column: account_name">self = &lt;tests.test_cleaning.TestCleaning testMethod=test_validate_required_columns&gt;

    def test_validate_required_columns(self) -&gt; None:
        """Test column validation logic."""
        # Test with all required columns
&gt;       self.assertTrue(validate_required_columns(self.sample_data))
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_cleaning.py:78: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

df =   Account ID    Account Name         Relationship Created Date
0        001       Acme Corp  Other/Miscellaneous   202...   003  Tech Solutions  Other/Miscellaneous   2021-01-03
3        004  Tech Solutions  Other/Miscellaneous   2021-01-04

    def validate_required_columns(df: pd.DataFrame) -&gt; bool:
        """Validate that required columns are present.
    
        Args:
            df: DataFrame to validate
    
        Returns:
            True if validation passes
    
        Raises:
            ValueError: If required columns are missing
    
        """
        # Use canonical column names since DataFrame has been renamed
        # Only check for columns that are actually mapped and renamed
        required_columns = [ACCOUNT_ID, ACCOUNT_NAME, CREATED_DATE]
    
        # Check for Account Name (required)
        if ACCOUNT_NAME not in df.columns:
&gt;           raise ValueError(f"Missing required name column: {ACCOUNT_NAME}")
E           ValueError: Missing required name column: account_name

src/cleaning.py:322: ValueError</failure></testcase><testcase classname="tests.test_cleanup.TestCleanupPlan" name="test_init" time="0.000" /><testcase classname="tests.test_cleanup.TestCleanupPlan" name="test_add_candidate" time="0.000" /><testcase classname="tests.test_cleanup.TestCleanupPlan" name="test_is_protected" time="0.000" /><testcase classname="tests.test_cleanup.TestCleanupPlan" name="test_get_protected_candidates" time="0.000" /><testcase classname="tests.test_cleanup.TestCleanupPlan" name="test_get_deletable_candidates" time="0.000" /><testcase classname="tests.test_cleanup.TestCleanupPlan" name="test_sort_candidates" time="0.000" /><testcase classname="tests.test_cleanup.TestRunTypeDetection" name="test_detect_test_run" time="0.000" /><testcase classname="tests.test_cleanup.TestRunTypeDetection" name="test_detect_dev_run" time="0.000" /><testcase classname="tests.test_cleanup.TestRunTypeDetection" name="test_detect_run_type_edge_cases" time="0.000" /><testcase classname="tests.test_cleanup.TestAgeCalculation" name="test_get_run_age_days_valid" time="0.000" /><testcase classname="tests.test_cleanup.TestAgeCalculation" name="test_get_run_age_days_invalid" time="0.000" /><testcase classname="tests.test_cleanup.TestCandidateDiscovery" name="test_discover_candidates_type_filter" time="0.001" /><testcase classname="tests.test_cleanup.TestCandidateDiscovery" name="test_discover_candidates_age_filter" time="0.000" /><testcase classname="tests.test_cleanup.TestCandidateDiscovery" name="test_discover_candidates_prod_sweep" time="0.001" /><testcase classname="tests.test_cleanup.TestCandidateDiscovery" name="test_discover_candidates_combined_filters" time="0.000" /><testcase classname="tests.test_cleanup.TestCandidateDiscovery" name="test_discover_candidates_deterministic" time="0.000" /><testcase classname="tests.test_cleanup.TestLatestSymlink" name="test_get_latest_run_id_valid" time="0.001" /><testcase classname="tests.test_cleanup.TestLatestSymlink" name="test_get_latest_run_id_not_exists" time="0.001" /><testcase classname="tests.test_cleanup.TestLatestSymlink" name="test_get_latest_run_id_not_symlink" time="0.001" /><testcase classname="tests.test_cleanup.TestLatestSymlink" name="test_get_latest_run_id_broken_symlink" time="0.001" /><testcase classname="tests.test_cleanup.TestIntegration" name="test_full_discovery_flow" time="0.001" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStatePathUtils" name="test_write_latest_pointer_none" time="0.002" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStatePathUtils" name="test_write_latest_pointer_with_run_id" time="0.002" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStatePathUtils" name="test_read_latest_run_id_none" time="0.001" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStatePathUtils" name="test_read_latest_run_id_valid" time="0.001" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStatePathUtils" name="test_read_latest_run_id_missing_file" time="0.000" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStatePathUtils" name="test_read_latest_run_id_invalid_json" time="0.001" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStateMiniDAG" name="test_resume_with_no_latest" time="0.001" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStateMiniDAG" name="test_get_smart_resume_stage_no_latest" time="0.001" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStateMiniDAG" name="test_validate_resume_capability_empty_state" time="0.001" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStateCleanup" name="test_cleanup_allow_empty_flag" time="0.001" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStateCleanup" name="test_cleanup_keep_at_least_config" time="0.001" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStateIntegration" name="test_empty_state_workflow" time="0.002" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStateIntegration" name="test_empty_state_symlink_handling" time="0.001" /><testcase classname="tests.test_cleanup_empty_state.TestEmptyStateIntegration" name="test_empty_state_error_handling" time="0.001" /><testcase classname="tests.test_cleanup_keep_at_least_guard" name="test_cleanup_keep_at_least_guard_logic" time="0.000" /><testcase classname="tests.test_cleanup_keep_at_least_guard" name="test_cleanup_keep_at_least_default_behavior" time="0.000" /><testcase classname="tests.test_cleanup_keep_at_least_guard" name="test_cleanup_keep_at_least_override_behavior" time="0.000" /><testcase classname="tests.test_cleanup_reconcile.TestCleanupReconcile" name="test_list_run_dirs_excludes_known_dirs" time="0.005" /><testcase classname="tests.test_cleanup_reconcile.TestCleanupReconcile" name="test_scan_filesystem_runs_combines_directories" time="0.001" /><testcase classname="tests.test_cleanup_reconcile.TestCleanupReconcile" name="test_discover_candidates_without_reconcile" time="0.000" /><testcase classname="tests.test_cleanup_reconcile.TestCleanupReconcile" name="test_discover_candidates_with_reconcile" time="0.000" /><testcase classname="tests.test_cleanup_reconcile.TestCleanupReconcile" name="test_orphan_directory_detected_in_dry_run" time="0.002" /><testcase classname="tests.test_cleanup_reconcile.TestCleanupReconcile" name="test_stale_index_detected" time="0.001" /><testcase classname="tests.test_cleanup_reconcile.TestCleanupReconcile" name="test_dry_run_flag_explicit" time="0.001" /><testcase classname="tests.test_cleanup_reconcile.TestCleanupReconcile" name="test_dry_run_vs_really_delete" time="0.000" /><testcase classname="tests.test_cleanup_reconcile.TestCleanupReconcile" name="test_reconcile_with_empty_index" time="0.001" /><testcase classname="tests.test_cleanup_reconcile.TestCleanupReconcile" name="test_json_output_with_reconcile" time="0.000" /><testcase classname="tests.test_cleanup_reconcile.TestCleanupReconcileIntegration" name="test_full_reconciliation_workflow" time="0.000" /><testcase classname="tests.test_cli_builder.TestGetAvailableInputFiles" name="test_get_available_input_files_empty_dir" time="0.001" /><testcase classname="tests.test_cli_builder.TestGetAvailableInputFiles" name="test_get_available_input_files_with_files" time="0.001" /><testcase classname="tests.test_cli_builder.TestGetAvailableConfigFiles" name="test_get_available_config_files_empty_dir" time="0.001" /><testcase classname="tests.test_cli_builder.TestGetAvailableConfigFiles" name="test_get_available_config_files_with_files" time="0.001" /><testcase classname="tests.test_cli_builder.TestValidateCliArgs" name="test_validate_cli_args_valid" time="0.001" /><testcase classname="tests.test_cli_builder.TestValidateCliArgs" name="test_validate_cli_args_missing_input" time="0.000" /><testcase classname="tests.test_cli_builder.TestValidateCliArgs" name="test_validate_cli_args_missing_config" time="0.000" /><testcase classname="tests.test_cli_builder.TestValidateCliArgs" name="test_validate_cli_args_nonexistent_input" time="0.001" /><testcase classname="tests.test_cli_builder.TestValidateCliArgs" name="test_validate_cli_args_nonexistent_config" time="0.001" /><testcase classname="tests.test_cli_builder.TestValidateCliArgs" name="test_validate_cli_args_invalid_workers_with_no_parallel" time="0.001" /><testcase classname="tests.test_cli_builder.TestValidateCliArgs" name="test_validate_cli_args_invalid_workers_value" time="0.001" /><testcase classname="tests.test_cli_builder.TestValidateCliArgs" name="test_validate_cli_args_invalid_backend" time="0.001" /><testcase classname="tests.test_cli_builder.TestValidateCliArgs" name="test_validate_cli_args_invalid_chunk_size" time="0.001" /><testcase classname="tests.test_cli_builder.TestValidateCliArgs" name="test_validate_cli_args_invalid_keep_runs" time="0.001" /><testcase classname="tests.test_cli_builder.TestValidateCliArgs" name="test_validate_cli_args_empty_run_id" time="0.001" /><testcase classname="tests.test_cli_builder.TestBuildCliCommand" name="test_build_cli_command_basic" time="0.001"><failure message="AssertionError: assert 'python src/c...settings.yaml' == 'python src/c...settings.yaml'&#10;  &#10;  Skipping 41 identical leading characters in diff, use -v to show&#10;  - est.csv --outdir data/processed --config config/settings.yaml&#10;  ?        ------------------------&#10;  + est.csv --config config/settings.yaml">self = &lt;tests.test_cli_builder.TestBuildCliCommand object at 0x12046cf80&gt;

    def test_build_cli_command_basic(self) -&gt; None:
        """Test basic command building."""
        cmd = build_cli_command(
            input_file="test.csv",
            config="settings.yaml",
        )
        expected = "python src/cleaning.py --input data/raw/test.csv --outdir data/processed --config config/settings.yaml"
&gt;       assert cmd == expected
E       AssertionError: assert 'python src/c...settings.yaml' == 'python src/c...settings.yaml'
E         
E         Skipping 41 identical leading characters in diff, use -v to show
E         - est.csv --outdir data/processed --config config/settings.yaml
E         ?        ------------------------
E         + est.csv --config config/settings.yaml

tests/test_cli_builder.py:207: AssertionError</failure></testcase><testcase classname="tests.test_cli_builder.TestBuildCliCommand" name="test_build_cli_command_with_parallelism" time="0.001"><failure message="AssertionError: assert 'python src/c...unk-size 1000' == 'python src/c...unk-size 1000'&#10;  &#10;  Skipping 41 identical leading characters in diff, use -v to show&#10;  - est.csv --outdir data/processed --config config/settings.yaml --workers 4 --parallel-backend threading --chunk-size 1000&#10;  ?        ------------------------&#10;  + est.csv --config config/settings.yaml --workers 4 --parallel-backend threading --chunk-size 1000">self = &lt;tests.test_cli_builder.TestBuildCliCommand object at 0x12046ca10&gt;

    def test_build_cli_command_with_parallelism(self) -&gt; None:
        """Test command with parallelism flags."""
        cmd = build_cli_command(
            input_file="test.csv",
            config="settings.yaml",
            workers=4,
            parallel_backend="threading",
            chunk_size=1000,
        )
        expected = "python src/cleaning.py --input data/raw/test.csv --outdir data/processed --config config/settings.yaml --workers 4 --parallel-backend threading --chunk-size 1000"
&gt;       assert cmd == expected
E       AssertionError: assert 'python src/c...unk-size 1000' == 'python src/c...unk-size 1000'
E         
E         Skipping 41 identical leading characters in diff, use -v to show
E         - est.csv --outdir data/processed --config config/settings.yaml --workers 4 --parallel-backend threading --chunk-size 1000
E         ?        ------------------------
E         + est.csv --config config/settings.yaml --workers 4 --parallel-backend threading --chunk-size 1000

tests/test_cli_builder.py:219: AssertionError</failure></testcase><testcase classname="tests.test_cli_builder.TestBuildCliCommand" name="test_build_cli_command_no_parallel" time="0.001"><failure message="AssertionError: assert 'python src/c...--no-parallel' == 'python src/c...--no-parallel'&#10;  &#10;  Skipping 41 identical leading characters in diff, use -v to show&#10;  - est.csv --outdir data/processed --config config/settings.yaml --no-parallel&#10;  ?        ------------------------&#10;  + est.csv --config config/settings.yaml --no-parallel">self = &lt;tests.test_cli_builder.TestBuildCliCommand object at 0x12046c7d0&gt;

    def test_build_cli_command_no_parallel(self) -&gt; None:
        """Test command with no-parallel flag."""
        cmd = build_cli_command(
            input_file="test.csv",
            config="settings.yaml",
            no_parallel=True,
        )
        expected = "python src/cleaning.py --input data/raw/test.csv --outdir data/processed --config config/settings.yaml --no-parallel"
&gt;       assert cmd == expected
E       AssertionError: assert 'python src/c...--no-parallel' == 'python src/c...--no-parallel'
E         
E         Skipping 41 identical leading characters in diff, use -v to show
E         - est.csv --outdir data/processed --config config/settings.yaml --no-parallel
E         ?        ------------------------
E         + est.csv --config config/settings.yaml --no-parallel

tests/test_cli_builder.py:229: AssertionError</failure></testcase><testcase classname="tests.test_cli_builder.TestBuildCliCommand" name="test_build_cli_command_with_run_control" time="0.001"><failure message="AssertionError: assert 'python src/c...--keep-runs 5' == 'python src/c...--keep-runs 5'&#10;  &#10;  Skipping 41 identical leading characters in diff, use -v to show&#10;  - est.csv --outdir data/processed --config config/settings.yaml --no-resume --run-id custom_run_123 --keep-runs 5&#10;  ?        ------------------------&#10;  + est.csv --config config/settings.yaml --no-resume --run-id custom_run_123 --keep-runs 5">self = &lt;tests.test_cli_builder.TestBuildCliCommand object at 0x12046c3b0&gt;

    def test_build_cli_command_with_run_control(self) -&gt; None:
        """Test command with run control flags."""
        cmd = build_cli_command(
            input_file="test.csv",
            config="settings.yaml",
            no_resume=True,
            run_id="custom_run_123",
            keep_runs=5,
        )
        expected = "python src/cleaning.py --input data/raw/test.csv --outdir data/processed --config config/settings.yaml --no-resume --run-id custom_run_123 --keep-runs 5"
&gt;       assert cmd == expected
E       AssertionError: assert 'python src/c...--keep-runs 5' == 'python src/c...--keep-runs 5'
E         
E         Skipping 41 identical leading characters in diff, use -v to show
E         - est.csv --outdir data/processed --config config/settings.yaml --no-resume --run-id custom_run_123 --keep-runs 5
E         ?        ------------------------
E         + est.csv --config config/settings.yaml --no-resume --run-id custom_run_123 --keep-runs 5

tests/test_cli_builder.py:241: AssertionError</failure></testcase><testcase classname="tests.test_cli_builder.TestBuildCliCommand" name="test_build_cli_command_with_extra_args" time="0.001"><failure message="AssertionError: assert 'python src/c...rbose --debug' == 'python src/c...rbose --debug'&#10;  &#10;  Skipping 41 identical leading characters in diff, use -v to show&#10;  - est.csv --outdir data/processed --config config/settings.yaml --verbose --debug&#10;  ?        ------------------------&#10;  + est.csv --config config/settings.yaml --verbose --debug">self = &lt;tests.test_cli_builder.TestBuildCliCommand object at 0x12046d580&gt;

    def test_build_cli_command_with_extra_args(self) -&gt; None:
        """Test command with extra arguments."""
        cmd = build_cli_command(
            input_file="test.csv",
            config="settings.yaml",
            extra_args="--verbose --debug",
        )
        expected = "python src/cleaning.py --input data/raw/test.csv --outdir data/processed --config config/settings.yaml --verbose --debug"
&gt;       assert cmd == expected
E       AssertionError: assert 'python src/c...rbose --debug' == 'python src/c...rbose --debug'
E         
E         Skipping 41 identical leading characters in diff, use -v to show
E         - est.csv --outdir data/processed --config config/settings.yaml --verbose --debug
E         ?        ------------------------
E         + est.csv --config config/settings.yaml --verbose --debug

tests/test_cli_builder.py:251: AssertionError</failure></testcase><testcase classname="tests.test_cli_builder.TestBuildCliCommand" name="test_build_cli_command_custom_outdir" time="0.001"><failure message="AssertionError: assert 'python src/c...custom/output' == 'python src/c...settings.yaml'&#10;  &#10;  Skipping 41 identical leading characters in diff, use -v to show&#10;  - est.csv --outdir custom/output --config config/settings.yaml&#10;  + est.csv --config config/settings.yaml --outdir custom/output">self = &lt;tests.test_cli_builder.TestBuildCliCommand object at 0x12046d700&gt;

    def test_build_cli_command_custom_outdir(self) -&gt; None:
        """Test command with custom output directory."""
        cmd = build_cli_command(
            input_file="test.csv",
            config="settings.yaml",
            outdir="custom/output",
        )
        expected = "python src/cleaning.py --input data/raw/test.csv --outdir custom/output --config config/settings.yaml"
&gt;       assert cmd == expected
E       AssertionError: assert 'python src/c...custom/output' == 'python src/c...settings.yaml'
E         
E         Skipping 41 identical leading characters in diff, use -v to show
E         - est.csv --outdir custom/output --config config/settings.yaml
E         + est.csv --config config/settings.yaml --outdir custom/output

tests/test_cli_builder.py:261: AssertionError</failure></testcase><testcase classname="tests.test_cli_builder.TestGetKnownRunIds" name="test_get_known_run_ids_success" time="0.000" /><testcase classname="tests.test_cli_builder.TestGetKnownRunIds" name="test_get_known_run_ids_empty" time="0.000" /><testcase classname="tests.test_cli_builder.TestGetKnownRunIds" name="test_get_known_run_ids_exception" time="0.000" /><testcase classname="tests.test_cli_resume_force" name="test_main_forwards_resume_noresume_force_correct_order" time="0.001" /><testcase classname="tests.test_cli_resume_force" name="test_main_forwards_resume_args_when_set" time="0.001" /><testcase classname="tests.test_details_fast_path.TestDetailsCache" name="test_cache_initialization" time="0.000" /><testcase classname="tests.test_details_fast_path.TestDetailsCache" name="test_cache_put_and_get" time="0.000" /><testcase classname="tests.test_details_fast_path.TestDetailsCache" name="test_cache_lru_eviction" time="0.000" /><testcase classname="tests.test_details_fast_path.TestDetailsCache" name="test_cache_invalidate_run" time="0.000" /><testcase classname="tests.test_details_fast_path.TestDetailsCache" name="test_cache_clear" time="0.000" /><testcase classname="tests.test_details_fast_path.TestParquetFingerprint" name="test_parquet_fingerprint_success" time="0.001" /><testcase classname="tests.test_details_fast_path.TestParquetFingerprint" name="test_parquet_fingerprint_file_not_found" time="0.000" /><testcase classname="tests.test_details_fast_path.TestGroupDetailsDuckDB" name="test_get_group_details_duckdb_success" time="0.003" /><testcase classname="tests.test_details_fast_path.TestGroupDetailsDuckDB" name="test_get_group_details_duckdb_file_not_found" time="0.007"><failure message="duckdb.duckdb.IOException: IO Error: No files found that match the pattern &quot;/test/path/group_details.parquet&quot;">self = &lt;tests.test_details_fast_path.TestGroupDetailsDuckDB object at 0x12046fd40&gt;
mock_exists = &lt;MagicMock name='exists' id='4841216848'&gt;
mock_get_paths = &lt;MagicMock name='get_artifact_paths' id='4847809408'&gt;

    @patch("src.utils.artifact_management.get_artifact_paths")
    @patch("os.path.exists")
    def test_get_group_details_duckdb_file_not_found(
        self,
        mock_exists: MagicMock,
        mock_get_paths: MagicMock,
    ) -&gt; None:
        """Test DuckDB details loading when file not found."""
        # Mock artifact paths
        mock_get_paths.return_value = {
            "group_details_parquet": "/test/path/group_details.parquet",
        }
        mock_exists.return_value = False
    
        # Test the function should raise FileNotFoundError
        with pytest.raises(FileNotFoundError):
&gt;           get_group_details_duckdb(
                "/test/path/group_details.parquet",
                "group1",
                "account_id",
                1,
                10,
                {},
                {},
            )

tests/test_details_fast_path.py:266: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parquet_path = '/test/path/group_details.parquet', group_id = 'group1'
order_by = 'account_id', page = 1, page_size = 10, filters = {}, settings = {}

    def _get_group_details_duckdb(
        parquet_path: str,
        group_id: str,
        order_by: str,
        page: int,
        page_size: int,
        filters: Dict[str, Any],
        settings: Dict[str, Any],
    ) -&gt; Tuple[List[Dict[str, Any]], int]:
        """DuckDB backend for group details (fast filtering + pagination)."""
        if DUCKDB is None:
            raise ImportError("DuckDB not available for group details")
    
        duckdb_threads = settings.get("ui", {}).get("duckdb_threads", 4)
        timeout_seconds = settings.get("ui", {}).get("timeout_seconds", 30)
    
        start = time.time()
    
        def check_timeout() -&gt; None:
            if time.time() - start &gt; timeout_seconds:
                raise DetailsFetchTimeout(f"Exceeded {timeout_seconds}s")
    
        # Get available columns dynamically
        available_columns = _get_available_columns(parquet_path)
        dynamic_select = _build_dynamic_select(available_columns)
    
        where_clause, params = _build_where_clause(filters, available_columns)
        # Clamp pagination inputs to avoid negative offsets and cap for performance
        page = max(1, int(page))
        requested_size = int(page_size)
        max_page_size = settings.get("ui", {}).get("max_page_size", 250)
        page_size = max(1, min(requested_size, max_page_size))
        if page_size != requested_size:  # Log when clamping occurs
            logger.info(
                "Page size clamped from %s to %s (max_page_size limit)",
                requested_size,
                max_page_size,
            )
            record_page_size_clamped()
        offset = (page - 1) * page_size
    
        # Build SQL using dynamic column selection
        sql = (
            dynamic_select + "WHERE " + GROUP_ID + " = ? AND " + where_clause + " "
            "ORDER BY "
            + order_by
            + " NULLS LAST, "
            + ACCOUNT_NAME
            + " ASC "  # order_by from get_order_by whitelist, stable tie-breaker, NULLs last
            "LIMIT ? OFFSET ?"
        )
        params_page = [parquet_path, group_id, *params, page_size, offset]
    
        count_sql = (
            "SELECT COUNT(*) FROM read_parquet(?) "
            "WHERE " + GROUP_ID + " = ? AND " + where_clause
        )
        params_count = [parquet_path, group_id, *params]
    
        conn = None
        try:
            conn = DUCKDB.connect(":memory:")
            duckdb_threads = int(duckdb_threads or 4)  # Ensure numeric
            duckdb_threads = min(duckdb_threads, 32)  # Double-enforce caps at call site
            conn.execute("PRAGMA threads=" + str(duckdb_threads))
            check_timeout()
    
&gt;           res = conn.execute(sql, params_page)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           duckdb.duckdb.IOException: IO Error: No files found that match the pattern "/test/path/group_details.parquet"

src/utils/group_details.py:398: IOException</failure></testcase><testcase classname="tests.test_details_fast_path.TestGroupDetailsDuckDB" name="test_get_group_details_duckdb_query_error" time="0.002" /><testcase classname="tests.test_details_fast_path.TestGroupsRouting" name="test_groups_use_duckdb_when_stats_parquet_exists" time="0.001"><failure message="AttributeError: module 'src.utils' has no attribute 'ui_helpers'">self = &lt;tests.test_details_fast_path.TestGroupsRouting object at 0x1204a0080&gt;
mock_exists = &lt;MagicMock name='exists' id='4848433056'&gt;
mock_get_paths = &lt;MagicMock name='get_artifact_paths' id='4852057344'&gt;

    @patch("src.utils.artifact_management.get_artifact_paths")
    @patch("os.path.exists")
    @patch("src.utils.opt_deps.DUCKDB_AVAILABLE", True)
    def test_groups_use_duckdb_when_stats_parquet_exists(
        self,
        mock_exists: MagicMock,
        mock_get_paths: MagicMock,
    ) -&gt; None:
        """Test that groups page uses DuckDB when group_stats.parquet exists."""
        from src.utils.group_pagination import get_groups_page
    
        # Mock artifact paths with group_stats.parquet
        mock_get_paths.return_value = {
            "group_stats_parquet": "/test/path/group_stats.parquet",
        }
        mock_exists.return_value = True
    
        # Mock the DuckDB function to return test data
&gt;       with patch(
            "src.utils.ui_helpers.get_groups_page_from_stats_duckdb",
        ) as mock_duckdb:

tests/test_details_fast_path.py:331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/Users/joe.j/.pyenv/versions/3.12.2/lib/python3.12/unittest/mock.py:1439: in __enter__
    self.target = self.getter()
                  ^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'src.utils.ui_helpers'

    def resolve_name(name):
        """
        Resolve a name to an object.
    
        It is expected that `name` will be a string in one of the following
        formats, where W is shorthand for a valid Python identifier and dot stands
        for a literal period in these pseudo-regexes:
    
        W(.W)*
        W(.W)*:(W(.W)*)?
    
        The first form is intended for backward compatibility only. It assumes that
        some part of the dotted name is a package, and the rest is an object
        somewhere within that package, possibly nested inside other objects.
        Because the place where the package stops and the object hierarchy starts
        can't be inferred by inspection, repeated attempts to import must be done
        with this form.
    
        In the second form, the caller makes the division point clear through the
        provision of a single colon: the dotted name to the left of the colon is a
        package to be imported, and the dotted name to the right is the object
        hierarchy within that package. Only one import is needed in this form. If
        it ends with the colon, then a module object is returned.
    
        The function will return an object (which might be a module), or raise one
        of the following exceptions:
    
        ValueError - if `name` isn't in a recognised format
        ImportError - if an import failed when it shouldn't have
        AttributeError - if a failure occurred when traversing the object hierarchy
                         within the imported package to get to the desired object.
        """
        global _NAME_PATTERN
        if _NAME_PATTERN is None:
            # Lazy import to speedup Python startup time
            import re
            dotted_words = r'(?!\d)(\w+)(\.(?!\d)(\w+))*'
            _NAME_PATTERN = re.compile(f'^(?P&lt;pkg&gt;{dotted_words})'
                                       f'(?P&lt;cln&gt;:(?P&lt;obj&gt;{dotted_words})?)?$',
                                       re.UNICODE)
    
        m = _NAME_PATTERN.match(name)
        if not m:
            raise ValueError(f'invalid format: {name!r}')
        gd = m.groupdict()
        if gd.get('cln'):
            # there is a colon - a one-step import is all that's needed
            mod = importlib.import_module(gd['pkg'])
            parts = gd.get('obj')
            parts = parts.split('.') if parts else []
        else:
            # no colon - have to iterate to find the package boundary
            parts = name.split('.')
            modname = parts.pop(0)
            # first part *must* be a module/package.
            mod = importlib.import_module(modname)
            while parts:
                p = parts[0]
                s = f'{modname}.{p}'
                try:
                    mod = importlib.import_module(s)
                    parts.pop(0)
                    modname = s
                except ImportError:
                    break
        # if we reach this point, mod is the module, already imported, and
        # parts is the list of parts in the object hierarchy to be traversed, or
        # an empty list if just the module is wanted.
        result = mod
        for p in parts:
&gt;           result = getattr(result, p)
                     ^^^^^^^^^^^^^^^^^^
E           AttributeError: module 'src.utils' has no attribute 'ui_helpers'

/Users/joe.j/.pyenv/versions/3.12.2/lib/python3.12/pkgutil.py:528: AttributeError</failure></testcase><testcase classname="tests.test_details_fast_path.TestGroupsRouting" name="test_groups_fallback_to_pyarrow_when_duckdb_unavailable" time="0.001"><failure message="AttributeError: module 'src.utils' has no attribute 'ui_helpers'">self = &lt;tests.test_details_fast_path.TestGroupsRouting object at 0x1204a01d0&gt;
mock_exists = &lt;MagicMock name='exists' id='4852064448'&gt;
mock_get_paths = &lt;MagicMock name='get_artifact_paths' id='4852070304'&gt;

    @patch("src.utils.artifact_management.get_artifact_paths")
    @patch("os.path.exists")
    @patch("src.utils.opt_deps.DUCKDB_AVAILABLE", False)
    def test_groups_fallback_to_pyarrow_when_duckdb_unavailable(
        self,
        mock_exists: MagicMock,
        mock_get_paths: MagicMock,
    ) -&gt; None:
        """Test that groups page falls back to PyArrow when DuckDB unavailable."""
        from src.utils.group_pagination import get_groups_page
    
        # Mock artifact paths with group_stats.parquet
        mock_get_paths.return_value = {
            "group_stats_parquet": "/test/path/group_stats.parquet",
        }
        mock_exists.return_value = True
    
        # Mock the PyArrow function to return test data
&gt;       with patch("src.utils.ui_helpers.get_groups_page_pyarrow") as mock_pyarrow:

tests/test_details_fast_path.py:362: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/Users/joe.j/.pyenv/versions/3.12.2/lib/python3.12/unittest/mock.py:1439: in __enter__
    self.target = self.getter()
                  ^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'src.utils.ui_helpers'

    def resolve_name(name):
        """
        Resolve a name to an object.
    
        It is expected that `name` will be a string in one of the following
        formats, where W is shorthand for a valid Python identifier and dot stands
        for a literal period in these pseudo-regexes:
    
        W(.W)*
        W(.W)*:(W(.W)*)?
    
        The first form is intended for backward compatibility only. It assumes that
        some part of the dotted name is a package, and the rest is an object
        somewhere within that package, possibly nested inside other objects.
        Because the place where the package stops and the object hierarchy starts
        can't be inferred by inspection, repeated attempts to import must be done
        with this form.
    
        In the second form, the caller makes the division point clear through the
        provision of a single colon: the dotted name to the left of the colon is a
        package to be imported, and the dotted name to the right is the object
        hierarchy within that package. Only one import is needed in this form. If
        it ends with the colon, then a module object is returned.
    
        The function will return an object (which might be a module), or raise one
        of the following exceptions:
    
        ValueError - if `name` isn't in a recognised format
        ImportError - if an import failed when it shouldn't have
        AttributeError - if a failure occurred when traversing the object hierarchy
                         within the imported package to get to the desired object.
        """
        global _NAME_PATTERN
        if _NAME_PATTERN is None:
            # Lazy import to speedup Python startup time
            import re
            dotted_words = r'(?!\d)(\w+)(\.(?!\d)(\w+))*'
            _NAME_PATTERN = re.compile(f'^(?P&lt;pkg&gt;{dotted_words})'
                                       f'(?P&lt;cln&gt;:(?P&lt;obj&gt;{dotted_words})?)?$',
                                       re.UNICODE)
    
        m = _NAME_PATTERN.match(name)
        if not m:
            raise ValueError(f'invalid format: {name!r}')
        gd = m.groupdict()
        if gd.get('cln'):
            # there is a colon - a one-step import is all that's needed
            mod = importlib.import_module(gd['pkg'])
            parts = gd.get('obj')
            parts = parts.split('.') if parts else []
        else:
            # no colon - have to iterate to find the package boundary
            parts = name.split('.')
            modname = parts.pop(0)
            # first part *must* be a module/package.
            mod = importlib.import_module(modname)
            while parts:
                p = parts[0]
                s = f'{modname}.{p}'
                try:
                    mod = importlib.import_module(s)
                    parts.pop(0)
                    modname = s
                except ImportError:
                    break
        # if we reach this point, mod is the module, already imported, and
        # parts is the list of parts in the object hierarchy to be traversed, or
        # an empty list if just the module is wanted.
        result = mod
        for p in parts:
&gt;           result = getattr(result, p)
                     ^^^^^^^^^^^^^^^^^^
E           AttributeError: module 'src.utils' has no attribute 'ui_helpers'

/Users/joe.j/.pyenv/versions/3.12.2/lib/python3.12/pkgutil.py:528: AttributeError</failure></testcase><testcase classname="tests.test_disposition.TestDisposition" name="test_apply_dispositions" time="0.022" /><testcase classname="tests.test_disposition.TestDisposition" name="test_blacklist_caching" time="0.002" /><testcase classname="tests.test_disposition.TestDisposition" name="test_blacklist_detection" time="0.002" /><testcase classname="tests.test_disposition.TestDisposition" name="test_blacklist_word_boundaries" time="0.002" /><testcase classname="tests.test_disposition.TestDisposition" name="test_disposition_classification" time="0.008" /><testcase classname="tests.test_disposition.TestDisposition" name="test_disposition_reasons" time="0.008" /><testcase classname="tests.test_disposition.TestDisposition" name="test_group_metadata_computation" time="0.005" /><testcase classname="tests.test_disposition.TestDisposition" name="test_manual_blacklist_application" time="0.002" /><testcase classname="tests.test_disposition.TestDisposition" name="test_manual_override_application" time="0.007"><failure message="AssertionError: 'primary_record' != 'manual_override:Delete'&#10;- primary_record&#10;+ manual_override:Delete">self = &lt;tests.test_disposition.TestDisposition testMethod=test_manual_override_application&gt;

    def test_manual_override_application(self) -&gt; None:
        """Test that manual overrides are applied correctly."""
        import json
        from pathlib import Path
    
        # Create test data
        test_data = pd.DataFrame(
            {
                "group_id": [1, 1],
                "Account Name": ["Acme Corp Inc", "Acme Corp Inc"],
                "is_primary": [True, False],
                "weakest_edge_to_primary": [100, 95],
                "suffix_class": ["INC", "INC"],
                "has_multiple_names": [False, False],
            },
        )
    
        # Create manual override file
        manual_dir = Path("data/manual")
        manual_dir.mkdir(parents=True, exist_ok=True)
    
        override_data = [
            {
                "record_id": "0",  # First record
                "account_id": "001Hs000054S8kI",
                "account_name": "Acme Corp Inc",
                "name_core": "acme corp",
                "override": "Delete",
                "reason": "Test override",
                "ts": "2024-01-01T00:00:00",
            },
        ]
    
        with open(manual_dir / "manual_dispositions.json", "w") as f:
            json.dump(override_data, f)
    
        try:
            # Apply dispositions
            result = apply_dispositions(test_data, self.settings)
    
            # Check that manual override was applied
            self.assertEqual(result.iloc[0]["disposition"], "Delete")
&gt;           self.assertEqual(
                result.iloc[0]["disposition_reason"],
                "manual_override:Delete",
            )
E           AssertionError: 'primary_record' != 'manual_override:Delete'
E           - primary_record
E           + manual_override:Delete

tests/test_disposition.py:301: AssertionError</failure></testcase><testcase classname="tests.test_disposition.TestDisposition" name="test_multiple_names_verification" time="0.009"><failure message="AssertionError: 'clean_singleton' != 'multi_name_string_requires_split'&#10;- clean_singleton&#10;+ multi_name_string_requires_split">self = &lt;tests.test_disposition.TestDisposition testMethod=test_multiple_names_verification&gt;

    def test_multiple_names_verification(self) -&gt; None:
        """Test that records with multiple names are marked as Verify."""
        # Create test data with multiple names
        df_groups = self.df_norm.copy()
        df_groups["group_id"] = [0, 1, 2, 3, 4, 5, 6, 7]
        df_groups["is_primary"] = [True] * 8
        df_groups["weakest_edge_to_primary"] = [0.0] * 8
    
        # Add multiple names flag
        df_groups.loc[0, "has_multiple_names"] = True
        df_groups.loc[1, "has_multiple_names"] = True
    
        df_dispositions = apply_dispositions(df_groups, self.settings)
    
        # Check that multiple names are marked as Verify
        self.assertEqual(df_dispositions.iloc[0]["disposition"], "Verify")
        self.assertEqual(df_dispositions.iloc[1]["disposition"], "Verify")
&gt;       self.assertEqual(
            df_dispositions.iloc[0]["disposition_reason"],
            "multi_name_string_requires_split",
        )
E       AssertionError: 'clean_singleton' != 'multi_name_string_requires_split'
E       - clean_singleton
E       + multi_name_string_requires_split

tests/test_disposition.py:254: AssertionError</failure></testcase><testcase classname="tests.test_disposition.TestDisposition" name="test_punctuation_stopword_detection" time="0.002" /><testcase classname="tests.test_disposition.TestDisposition" name="test_short_long_name_detection" time="0.002" /><testcase classname="tests.test_disposition.TestDisposition" name="test_strong_match_same_suffix" time="0.008" /><testcase classname="tests.test_disposition.TestDisposition" name="test_suffix_mismatch_verification" time="0.008" /><testcase classname="tests.test_disposition.TestDisposition" name="test_suspicious_singleton_detection" time="0.002" /><testcase classname="tests.test_dtypes.TestDtypeApplication" name="test_apply_dtypes_basic" time="0.001" /><testcase classname="tests.test_dtypes.TestDtypeApplication" name="test_apply_dtypes_missing_columns" time="0.001" /><testcase classname="tests.test_dtypes.TestDtypeApplication" name="test_apply_dtypes_empty_dataframe" time="0.000" /><testcase classname="tests.test_dtypes.TestObjectColumnValidation" name="test_assert_no_unexpected_object_columns_pass" time="0.001" /><testcase classname="tests.test_dtypes.TestObjectColumnValidation" name="test_assert_no_unexpected_object_columns_fail" time="0.001" /><testcase classname="tests.test_dtypes.TestObjectColumnValidation" name="test_assert_no_unexpected_object_columns_empty" time="0.000" /><testcase classname="tests.test_dtypes.TestObjectColumnValidation" name="test_assert_no_unexpected_object_columns_custom_allowed" time="0.000" /><testcase classname="tests.test_dtypes.TestIntermediateColumnDropping" name="test_drop_intermediate_columns" time="0.001" /><testcase classname="tests.test_dtypes.TestIntermediateColumnDropping" name="test_drop_intermediate_columns_none_present" time="0.000" /><testcase classname="tests.test_dtypes.TestMemoryOptimization" name="test_optimize_dataframe_memory_basic" time="0.005" /><testcase classname="tests.test_dtypes.TestMemoryOptimization" name="test_optimize_dataframe_memory_empty" time="0.000" /><testcase classname="tests.test_dtypes.TestMemoryOptimization" name="test_optimize_dataframe_memory_with_intermediate_columns" time="0.002" /><testcase classname="tests.test_dtypes.TestSchemaDetection" name="test_get_dtypes_for_schema_accounts" time="0.000" /><testcase classname="tests.test_dtypes.TestSchemaDetection" name="test_get_dtypes_for_schema_pairs" time="0.000" /><testcase classname="tests.test_dtypes.TestSchemaDetection" name="test_get_dtypes_for_schema_groups" time="0.000" /><testcase classname="tests.test_dtypes.TestSchemaDetection" name="test_get_dtypes_for_schema_review_ready" time="0.000" /><testcase classname="tests.test_dtypes.TestSchemaDetection" name="test_get_dtypes_for_schema_unknown" time="0.000" /><testcase classname="tests.test_dtypes.TestDtypeMapConstants" name="test_dtypes_structure" time="0.000" /><testcase classname="tests.test_dtypes.TestDtypeMapConstants" name="test_allowed_object_columns" time="0.000" /><testcase classname="tests.test_dtypes.TestDtypeMapConstants" name="test_intermediate_columns_to_drop" time="0.000" /><testcase classname="tests.test_duckdb_query_params" name="test_no_f_string_sql_queries" time="0.021"><failure message="Failed: Found f-string SQL queries. All DuckDB queries must use parameterized placeholders:&#10;src/utils/group_pagination.py: 1 f-string SQL queries found&#10;src/utils/group_details.py: 2 f-string SQL queries found&#10;&#10;Example of correct usage:&#10;query = 'SELECT * FROM groups WHERE run_id = ?'&#10;result = conn.execute(query, [run_id]).fetchdf()">def test_no_f_string_sql_queries():
        """Verify no f-string SQL queries exist in group-related modules.
    
        This test ensures all DuckDB queries use parameterized placeholders
        instead of string interpolation to prevent SQL injection.
        """
        # Files to check for SQL queries
        sql_files = [
            "src/utils/group_pagination.py",
            "src/utils/group_details.py",
            "src/utils/group_stats.py",
            "src/utils/filtering.py",
        ]
    
        violations = []
    
        for file_path in sql_files:
            if Path(file_path).exists():
                f_strings = find_string_interpolations(file_path)
                if f_strings:
                    violations.append(
                        f"{file_path}: {len(f_strings)} f-string SQL queries found",
                    )
    
        if violations:
&gt;           pytest.fail(
                "Found f-string SQL queries. All DuckDB queries must use parameterized placeholders:\n"
                + "\n".join(violations)
                + "\n\nExample of correct usage:\n"
                + "query = 'SELECT * FROM groups WHERE run_id = ?'\n"
                + "result = conn.execute(query, [run_id]).fetchdf()",
            )
E           Failed: Found f-string SQL queries. All DuckDB queries must use parameterized placeholders:
E           src/utils/group_pagination.py: 1 f-string SQL queries found
E           src/utils/group_details.py: 2 f-string SQL queries found
E           
E           Example of correct usage:
E           query = 'SELECT * FROM groups WHERE run_id = ?'
E           result = conn.execute(query, [run_id]).fetchdf()

tests/test_duckdb_query_params.py:170: Failed</failure></testcase><testcase classname="tests.test_duckdb_query_params" name="test_duckdb_parameterization_examples" time="0.007" /><testcase classname="tests.test_duckdb_query_params" name="test_sql_injection_prevention" time="0.011" /><testcase classname="tests.test_e2e_run_id_and_determinism" name="test_e2e_determinism" time="0.000"><skipped type="pytest.skip" message="Test input file not found: data/raw/sample_test.csv">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_e2e_run_id_and_determinism.py:111: Test input file not found: data/raw/sample_test.csv</skipped></testcase><testcase classname="tests.test_e2e_run_id_and_determinism" name="test_run_id_scoping" time="0.000"><skipped type="pytest.skip" message="Test input file not found: data/raw/sample_test.csv">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_e2e_run_id_and_determinism.py:194: Test input file not found: data/raw/sample_test.csv</skipped></testcase><testcase classname="tests.test_e2e_run_id_and_determinism" name="test_no_legacy_paths" time="0.000"><skipped type="pytest.skip" message="Test input file not found: data/raw/sample_test.csv">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_e2e_run_id_and_determinism.py:232: Test input file not found: data/raw/sample_test.csv</skipped></testcase><testcase classname="tests.test_e2e_run_id_and_determinism" name="test_latest_pointer" time="0.001"><skipped type="pytest.skip" message="Test input file not found: data/raw/sample_test.csv">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_e2e_run_id_and_determinism.py:262: Test input file not found: data/raw/sample_test.csv</skipped></testcase><testcase classname="tests.test_env_clamp" name="test_ensure_single_thread_blas_sets_unset_vars" time="0.000" /><testcase classname="tests.test_env_clamp" name="test_ensure_single_thread_blas_respects_existing_values" time="0.000" /><testcase classname="tests.test_env_clamp" name="test_ensure_single_thread_blas_mixed_scenario" time="0.000" /><testcase classname="tests.test_env_clamp" name="test_parallel_map_uses_blas_clamp" time="0.281" /><testcase classname="tests.test_env_clamp" name="test_parallel_map_sequential_fallback" time="0.028" /><testcase classname="tests.test_exact_equals_phase1352" name="test_build_raw_exact_key" time="0.001" /><testcase classname="tests.test_exact_equals_phase1352" name="test_find_exact_equals_groups" time="0.006" /><testcase classname="tests.test_exact_equals_phase1352" name="test_create_unique_normalized" time="0.001" /><testcase classname="tests.test_exact_equals_phase1352" name="test_no_exact_groups" time="0.003" /><testcase classname="tests.test_exact_equals_phase1352" name="test_min_group_size_filtering" time="0.004" /><testcase classname="tests.test_fragment_utils" name="test_fragment_decorator_availability" time="0.000" /><testcase classname="tests.test_fragment_utils" name="test_fragment_api_detection" time="0.000" /><testcase classname="tests.test_fragment_utils" name="test_stable_fragment_detection" time="0.001" /><testcase classname="tests.test_fragment_utils" name="test_experimental_fragment_detection" time="0.001" /><testcase classname="tests.test_fragment_utils" name="test_fragment_import_smoke" time="0.000" /><testcase classname="tests.test_fragment_utils" name="test_fragment_decorator_functionality" time="0.000" /><testcase classname="tests.test_group_artifacts_scoped" name="test_group_artifacts_scoped" time="0.001" /><testcase classname="tests.test_group_artifacts_scoped" name="test_artifact_paths_never_global" time="0.001" /><testcase classname="tests.test_group_artifacts_scoped" name="test_run_id_required_for_processed_paths" time="0.001" /><testcase classname="tests.test_group_artifacts_scoped" name="test_path_utils_consistency" time="0.000" /><testcase classname="tests.test_group_stats_memoization.TestGroupStatsMemoization" name="test_duckdb_memoization_smoke" time="0.228" /><testcase classname="tests.test_group_stats_memoization.TestGroupStatsMemoization" name="test_duckdb_memoization_different_configs" time="0.018" /><testcase classname="tests.test_group_stats_memoization.TestGroupStatsMemoization" name="test_duckdb_memoization_disabled" time="0.014" /><testcase classname="tests.test_group_stats_memoization.TestGroupStatsMemoization" name="test_duckdb_memoization_performance_improvement" time="0.020" /><testcase classname="tests.test_grouping.TestConfigHash" name="test_config_hash_deterministic" time="0.000" /><testcase classname="tests.test_grouping.TestConfigHash" name="test_config_hash_different_for_different_configs" time="0.000" /><testcase classname="tests.test_grouping.TestStableGroupId" name="test_stable_group_id_deterministic" time="0.000" /><testcase classname="tests.test_grouping.TestStableGroupId" name="test_stable_group_id_order_independent" time="0.000" /><testcase classname="tests.test_grouping.TestStableGroupId" name="test_stable_group_id_config_dependent" time="0.000" /><testcase classname="tests.test_grouping.TestCanJoinGroup" name="test_can_join_high_threshold" time="0.000" /><testcase classname="tests.test_grouping.TestCanJoinGroup" name="test_can_join_medium_with_shared_token" time="0.000" /><testcase classname="tests.test_grouping.TestCanJoinGroup" name="test_cannot_join_insufficient_edge" time="0.000" /><testcase classname="tests.test_grouping.TestCanJoinGroup" name="test_cannot_join_no_shared_tokens" time="0.000" /><testcase classname="tests.test_grouping.TestCanopyBound" name="test_canopy_bound_under_limit" time="0.000" /><testcase classname="tests.test_grouping.TestCanopyBound" name="test_canopy_bound_over_limit_with_high_edge" time="0.000" /><testcase classname="tests.test_grouping.TestCanopyBound" name="test_canopy_bound_over_limit_without_high_edge" time="0.000" /><testcase classname="tests.test_grouping.TestCanopyBound" name="test_canopy_bound_disabled" time="0.000" /><testcase classname="tests.test_grouping.TestGroupCreation" name="test_create_groups_with_edge_gating" time="0.010" /><testcase classname="tests.test_grouping.TestGroupCreation" name="test_create_groups_standard_fallback" time="0.004" /><testcase classname="tests.test_groups_pagination.TestSortExpression" name="test_build_sort_expression_group_size_desc" time="0.000" /><testcase classname="tests.test_groups_pagination.TestSortExpression" name="test_build_sort_expression_group_size_asc" time="0.000" /><testcase classname="tests.test_groups_pagination.TestSortExpression" name="test_build_sort_expression_max_score_desc" time="0.000" /><testcase classname="tests.test_groups_pagination.TestSortExpression" name="test_build_sort_expression_max_score_asc" time="0.000" /><testcase classname="tests.test_groups_pagination.TestSortExpression" name="test_build_sort_expression_account_name_asc" time="0.000" /><testcase classname="tests.test_groups_pagination.TestSortExpression" name="test_build_sort_expression_account_name_desc" time="0.000" /><testcase classname="tests.test_groups_pagination.TestSortExpression" name="test_build_sort_expression_unknown" time="0.000" /><testcase classname="tests.test_groups_pagination.TestCacheKeyGeneration" name="test_build_cache_key_basic" time="0.000" /><testcase classname="tests.test_groups_pagination.TestCacheKeyGeneration" name="test_build_cache_key_filter_changes" time="0.000" /><testcase classname="tests.test_groups_pagination.TestCacheKeyGeneration" name="test_build_cache_key_sort_changes" time="0.000" /><testcase classname="tests.test_groups_pagination.TestCacheKeyGeneration" name="test_build_cache_key_page_changes" time="0.001" /><testcase classname="tests.test_groups_pagination.TestGroupStatsComputation" name="test_compute_group_stats_basic" time="0.009" /><testcase classname="tests.test_groups_pagination.TestGroupStatsComputation" name="test_compute_group_stats_primary_names" time="0.008" /><testcase classname="tests.test_groups_pagination.TestGroupStatsComputation" name="test_compute_group_stats_no_primary" time="0.009"><failure message="AssertionError: assert None == 'Company A'">self = &lt;tests.test_groups_pagination.TestGroupStatsComputation object at 0x120524d40&gt;

    def test_compute_group_stats_no_primary(self) -&gt; None:
        """Test handling when no primary record exists."""
        data: Dict[str, List[Any]] = {
            "group_id": ["group1", "group1"],
            "account_name": ["Company A", "Company B"],
            "is_primary": [False, False],
            "weakest_edge_to_primary": [95.0, 85.0],
        }
    
        table = pa.Table.from_pydict(data)
        df = table.to_pandas()
        stats_table = compute_group_stats(df)
        stats_df = stats_table
    
        group1_stats = stats_df[stats_df["group_id"] == "group1"].iloc[0]
&gt;       assert group1_stats["primary_name"] == "Company A"  # First record
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AssertionError: assert None == 'Company A'

tests/test_groups_pagination.py:197: AssertionError</failure></testcase><testcase classname="tests.test_groups_pagination.TestFilterApplication" name="test_apply_filters_pyarrow_disposition" time="0.001" /><testcase classname="tests.test_groups_pagination.TestFilterApplication" name="test_apply_filters_pyarrow_edge_strength" time="0.000"><failure message="TypeError: Got unexpected argument type &lt;class 'pyarrow._compute.Expression'&gt; for compute function">self = &lt;tests.test_groups_pagination.TestFilterApplication object at 0x1205250a0&gt;

    def test_apply_filters_pyarrow_edge_strength(self) -&gt; None:
        """Test edge strength filtering."""
        data: Dict[str, List[Any]] = {
            "group_id": ["group1", "group2", "group3"],
            "weakest_edge_to_primary": [95.0, 85.0, 75.0],
        }
    
        table = pa.Table.from_pydict(data)
        filters = {"min_edge_strength": 80.0}
    
&gt;       filtered_table = apply_filters_pyarrow(table, filters)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_groups_pagination.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/utils/filtering.py:157: in apply_filters_pyarrow
    es_mask = pc.greater_equal(
/Users/joe.j/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pyarrow/compute.py:252: in wrapper
    return func.call(args, None, memory_pool)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pyarrow/_compute.pyx:386: in pyarrow._compute.Function.call
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

&gt;   ???
E   TypeError: Got unexpected argument type &lt;class 'pyarrow._compute.Expression'&gt; for compute function

pyarrow/_compute.pyx:519: TypeError</failure></testcase><testcase classname="tests.test_groups_pagination.TestFilterApplication" name="test_apply_filters_pyarrow_no_filters" time="0.000" /><testcase classname="tests.test_groups_pagination.TestPaginationLimits" name="test_pagination_limits_empty_data" time="0.001" /><testcase classname="tests.test_groups_pagination.TestPaginationLimits" name="test_pagination_limits_page_bounds" time="0.001"><failure message="assert 0 == 5&#10; +  where 0 = len([])">self = &lt;tests.test_groups_pagination.TestPaginationLimits object at 0x1205255b0&gt;

    def test_pagination_limits_page_bounds(self) -&gt; None:
        """Test pagination with page bounds."""
        # Create test data with known number of groups
        data: Dict[str, List[Any]] = {
            "group_id": [f"group{i}" for i in range(10)],
            "account_name": [f"Company {i}" for i in range(10)],
            "is_primary": [True] + [False] * 9,
            "weakest_edge_to_primary": [95.0] * 10,
        }
    
        with tempfile.TemporaryDirectory() as temp_dir:
            table = pa.Table.from_pydict(data)
            parquet_path = os.path.join(temp_dir, "review_ready.parquet")
            pa.parquet.write_table(table, parquet_path)
    
            # Mock artifact paths
            def mock_get_artifact_paths(run_id: str) -&gt; Dict[str, str]:
                return {"review_ready_parquet": parquet_path}
    
            import src.utils.artifact_management
    
            original_get_artifact_paths = (
                src.utils.artifact_management.get_artifact_paths
            )
            src.utils.artifact_management.get_artifact_paths = mock_get_artifact_paths
    
            try:
                # Test first page
                page_groups, total_count = get_groups_page_pyarrow(
                    "test_run",
                    "Group Size (Desc)",
                    1,
                    5,
                    {},
                )
    
&gt;               assert len(page_groups) == 5
E               assert 0 == 5
E                +  where 0 = len([])

tests/test_groups_pagination.py:333: AssertionError</failure></testcase><testcase classname="tests.test_groups_pagination.TestSortingStability" name="test_sorting_stability_group_id_tiebreaker" time="0.002"><failure message="AssertionError: assert [] == ['group_a', '...b', 'group_c']&#10;  &#10;  Right contains 3 more items, first extra item: 'group_a'&#10;  Use -v to get more diff">self = &lt;tests.test_groups_pagination.TestSortingStability object at 0x1205255e0&gt;

    def test_sorting_stability_group_id_tiebreaker(self) -&gt; None:
        """Test that group_id tiebreaker ensures stable sorting."""
        # Create test data with same values but different group_ids
        data: Dict[str, List[Any]] = {
            "group_id": [
                "group_b",
                "group_b",
                "group_a",
                "group_a",
                "group_c",
                "group_c",
            ],
            "account_name": [
                "Company B1",
                "Company B2",
                "Company A1",
                "Company A2",
                "Company C1",
                "Company C2",
            ],
            "is_primary": [True, False, True, False, True, False],
            "weakest_edge_to_primary": [90.0, 90.0, 90.0, 90.0, 90.0, 90.0],
        }
    
        with tempfile.TemporaryDirectory() as temp_dir:
            table = pa.Table.from_pydict(data)
            parquet_path = os.path.join(temp_dir, "review_ready.parquet")
            pa.parquet.write_table(table, parquet_path)
    
            # Mock artifact paths
            def mock_get_artifact_paths(run_id: str) -&gt; Dict[str, str]:
                return {"review_ready_parquet": parquet_path}
    
            import src.utils.artifact_management
    
            original_get_artifact_paths = (
                src.utils.artifact_management.get_artifact_paths
            )
            src.utils.artifact_management.get_artifact_paths = mock_get_artifact_paths
    
            try:
                # Test ascending sort - should be stable by group_id
                page_groups, _ = get_groups_page_pyarrow(
                    "test_run",
                    "Group Size (Asc)",
                    1,
                    10,
                    {},
                )
    
                # Should be sorted by group_id (ascending) as tiebreaker
                group_ids = [group["group_id"] for group in page_groups]
&gt;               assert group_ids == ["group_a", "group_b", "group_c"]
E               AssertionError: assert [] == ['group_a', '...b', 'group_c']
E                 
E                 Right contains 3 more items, first extra item: 'group_a'
E                 Use -v to get more diff

tests/test_groups_pagination.py:420: AssertionError</failure></testcase><testcase classname="tests.test_groups_pagination.TestCacheKeyInvalidation" name="test_cache_key_changes_on_sort" time="0.001" /><testcase classname="tests.test_groups_pagination.TestCacheKeyInvalidation" name="test_cache_key_changes_on_filters" time="0.001" /><testcase classname="tests.test_groups_pagination.TestCacheKeyInvalidation" name="test_cache_key_changes_on_page" time="0.001" /><testcase classname="tests.test_id_utils.TestChunkChecksum" name="test_chunk_checksum_all_lowercase" time="0.000" /><testcase classname="tests.test_id_utils.TestChunkChecksum" name="test_chunk_checksum_all_uppercase" time="0.000" /><testcase classname="tests.test_id_utils.TestChunkChecksum" name="test_chunk_checksum_mixed_case" time="0.000" /><testcase classname="tests.test_id_utils.TestChunkChecksum" name="test_chunk_checksum_with_numbers" time="0.000" /><testcase classname="tests.test_id_utils.TestChunkChecksum" name="test_chunk_checksum_wrong_length" time="0.001" /><testcase classname="tests.test_id_utils.TestSfid15To18" name="test_sfid15_to_18_known_cases" time="0.000" /><testcase classname="tests.test_id_utils.TestSfid15To18" name="test_sfid15_to_18_case_sensitivity" time="0.000" /><testcase classname="tests.test_id_utils.TestSfid15To18" name="test_sfid15_to_18_with_numbers" time="0.000" /><testcase classname="tests.test_id_utils.TestSfid15To18" name="test_sfid15_to_18_invalid_inputs" time="0.002" /><testcase classname="tests.test_id_utils.TestNormalizeSfidSeries" name="test_normalize_sfid_series_15_to_18" time="0.003" /><testcase classname="tests.test_id_utils.TestNormalizeSfidSeries" name="test_normalize_sfid_series_pass_through_18" time="0.001" /><testcase classname="tests.test_id_utils.TestNormalizeSfidSeries" name="test_normalize_sfid_series_mixed_15_and_18" time="0.002" /><testcase classname="tests.test_id_utils.TestNormalizeSfidSeries" name="test_normalize_sfid_series_handles_whitespace" time="0.002" /><testcase classname="tests.test_id_utils.TestNormalizeSfidSeries" name="test_normalize_sfid_series_handles_nan" time="0.002" /><testcase classname="tests.test_id_utils.TestNormalizeSfidSeries" name="test_normalize_sfid_series_empty_series" time="0.000" /><testcase classname="tests.test_id_utils.TestNormalizeSfidSeries" name="test_normalize_sfid_series_invalid_ids" time="0.003" /><testcase classname="tests.test_id_utils.TestNormalizeSfidSeries" name="test_normalize_sfid_series_invalid_characters" time="0.002" /><testcase classname="tests.test_id_utils.TestValidateSfidFormat" name="test_validate_sfid_format_valid_15_char" time="0.000" /><testcase classname="tests.test_id_utils.TestValidateSfidFormat" name="test_validate_sfid_format_valid_18_char" time="0.000" /><testcase classname="tests.test_id_utils.TestValidateSfidFormat" name="test_validate_sfid_format_invalid_lengths" time="0.000" /><testcase classname="tests.test_id_utils.TestValidateSfidFormat" name="test_validate_sfid_format_invalid_characters" time="0.000" /><testcase classname="tests.test_id_utils.TestValidateSfidFormat" name="test_validate_sfid_format_non_string" time="0.000" /><testcase classname="tests.test_import_audit" name="test_import_src_utils" time="0.001" /><testcase classname="tests.test_import_audit" name="test_import_app_components" time="0.003" /><testcase classname="tests.test_import_audit" name="test_import_app_modules" time="0.002" /><testcase classname="tests.test_import_audit" name="test_import_src_modules" time="0.000" /><testcase classname="tests.test_import_audit" name="test_import_src_utils_submodules" time="0.000" /><testcase classname="tests.test_import_audit" name="test_absolute_imports_work" time="0.000" /><testcase classname="tests.test_import_audit" name="test_no_relative_imports" time="0.000" /><testcase classname="tests.test_import_audit" name="test_circular_imports" time="0.000" /><testcase classname="tests.test_import_audit" name="test_component_imports" time="0.000" /><testcase classname="tests.test_import_audit" name="test_utils_no_streamlit_imports" time="0.000" /><testcase classname="tests.test_imports" name="test_absolute_imports" time="0.000"><failure message="Failed: Failed to import src.salesforce: No module named 'src.salesforce'">def test_absolute_imports() -&gt; None:
        """Test that all modules can be imported using absolute imports."""
        modules_to_test = [
            # Core modules
            "src.utils.cache_utils",
            "src.utils.dtypes",
            "src.utils.hash_utils",
            "src.utils.io_utils",
            "src.utils.logging_utils",
            "src.utils.parallel_utils",
            "src.utils.path_utils",
            "src.utils.perf_utils",
            "src.utils.resource_monitor",
            "src.utils.sort_utils",
            "src.utils.state_utils",
            "src.utils.validation_utils",
            "src.utils.fragment_utils",  # Phase 1.18.3 addition
            # "src.utils.ui_helpers",  # Deprecated - moved to deprecated/ folder
            "src.alias_matching",
            "src.cleaning",
            "src.disposition",
            "src.grouping",
            "src.manual_io",
            "src.normalize",
            "src.performance",
            "src.salesforce",
            "src.similarity",
            "src.survivorship",
            # App modules
            "app.components.controls",
            "app.components.export",
            "app.components.group_details",
            "app.components.group_list",
            "app.components.maintenance",
            "app.main",
        ]
    
        for module_name in modules_to_test:
            try:
&gt;               module = __import__(module_name, fromlist=[""])
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E               ModuleNotFoundError: No module named 'src.salesforce'

tests/test_imports.py:49: ModuleNotFoundError

During handling of the above exception, another exception occurred:

    def test_absolute_imports() -&gt; None:
        """Test that all modules can be imported using absolute imports."""
        modules_to_test = [
            # Core modules
            "src.utils.cache_utils",
            "src.utils.dtypes",
            "src.utils.hash_utils",
            "src.utils.io_utils",
            "src.utils.logging_utils",
            "src.utils.parallel_utils",
            "src.utils.path_utils",
            "src.utils.perf_utils",
            "src.utils.resource_monitor",
            "src.utils.sort_utils",
            "src.utils.state_utils",
            "src.utils.validation_utils",
            "src.utils.fragment_utils",  # Phase 1.18.3 addition
            # "src.utils.ui_helpers",  # Deprecated - moved to deprecated/ folder
            "src.alias_matching",
            "src.cleaning",
            "src.disposition",
            "src.grouping",
            "src.manual_io",
            "src.normalize",
            "src.performance",
            "src.salesforce",
            "src.similarity",
            "src.survivorship",
            # App modules
            "app.components.controls",
            "app.components.export",
            "app.components.group_details",
            "app.components.group_list",
            "app.components.maintenance",
            "app.main",
        ]
    
        for module_name in modules_to_test:
            try:
                module = __import__(module_name, fromlist=[""])
                assert module is not None
            except ImportError as e:
&gt;               pytest.fail(f"Failed to import {module_name}: {e}")
E               Failed: Failed to import src.salesforce: No module named 'src.salesforce'

tests/test_imports.py:52: Failed</failure></testcase><testcase classname="tests.test_imports" name="test_component_imports" time="0.000" /><testcase classname="tests.test_imports" name="test_utils_imports" time="0.000" /><testcase classname="tests.test_interrupt_resume.TestMiniDAGInterruptHandling" name="test_mark_interrupted" time="0.002" /><testcase classname="tests.test_interrupt_resume.TestMiniDAGInterruptHandling" name="test_get_current_stage" time="0.003" /><testcase classname="tests.test_interrupt_resume.TestMiniDAGInterruptHandling" name="test_interrupted_status_type" time="0.001" /><testcase classname="tests.test_interrupt_resume.TestInterruptResumeIntegration" name="test_interrupt_resume_workflow" time="0.708"><failure message="AssertionError: Pipeline failed: Traceback (most recent call last):&#10;    File &quot;/Users/joe.j/Documents/dev/salesforce/apps/company_junction/src/cleaning.py&quot;, line 24, in &lt;module&gt;&#10;      from src.alias_matching import (&#10;  ModuleNotFoundError: No module named 'src'&#10;  &#10;assert 1 == 0&#10; +  where 1 = CompletedProcess(args=['/Users/joe.j/.pyenv/versions/3.12.2/bin/python3.12', 'src/cleaning.py', '--input', '/var/folde...aning.py&quot;, line 24, in &lt;module&gt;\n    from src.alias_matching import (\nModuleNotFoundError: No module named \'src\'\n').returncode">self = &lt;tests.test_interrupt_resume.TestInterruptResumeIntegration object at 0x120526cc0&gt;

        def test_interrupt_resume_workflow(self) -&gt; None:
            """Test the complete interrupt and resume workflow."""
            # Create test CSV
            csv_path = self.create_test_csv("test_interrupt.csv", 5)
    
            try:
                # Create temporary directories
                temp_dir = tempfile.mkdtemp()
                interim_dir = os.path.join(temp_dir, "interim")
                processed_dir = os.path.join(temp_dir, "processed")
                os.makedirs(interim_dir)
                os.makedirs(processed_dir)
    
                # Create a minimal config
                config_path = os.path.join(temp_dir, "test_config.yaml")
                with open(config_path, "w") as f:
                    f.write(
                        """
    similarity:
      high: 92
      medium: 84
      penalty:
        suffix_mismatch: 25
        num_style_mismatch: 5
    parallelism:
      workers: 1
      backend: "threading"
      chunk_size: 1000
      small_input_threshold: 1000
    """,
                    )
    
                # Test that we can run a small pipeline
                cmd = [
                    sys.executable,
                    "src/cleaning.py",
                    "--input",
                    csv_path,
                    "--outdir",
                    processed_dir,
                    "--config",
                    config_path,
                    "--workers",
                    "1",
                    "--parallel-backend",
                    "threading",
                    "--no-resume",
                ]
    
                # Run the pipeline (should complete quickly with small data)
                result = subprocess.run(
                    cmd, check=False, capture_output=True, text=True, timeout=30
                )
    
                # Should complete successfully
&gt;               assert result.returncode == 0, f"Pipeline failed: {result.stderr}"
E               AssertionError: Pipeline failed: Traceback (most recent call last):
E                   File "/Users/joe.j/Documents/dev/salesforce/apps/company_junction/src/cleaning.py", line 24, in &lt;module&gt;
E                     from src.alias_matching import (
E                 ModuleNotFoundError: No module named 'src'
E                 
E               assert 1 == 0
E                +  where 1 = CompletedProcess(args=['/Users/joe.j/.pyenv/versions/3.12.2/bin/python3.12', 'src/cleaning.py', '--input', '/var/folde...aning.py", line 24, in &lt;module&gt;\n    from src.alias_matching import (\nModuleNotFoundError: No module named \'src\'\n').returncode

tests/test_interrupt_resume.py:169: AssertionError</failure></testcase><testcase classname="tests.test_interrupt_resume.TestInterruptResumeIntegration" name="test_keyboard_interrupt_handling" time="0.007" /><testcase classname="tests.test_interrupt_resume.TestRunStatusInterrupted" name="test_update_run_status_interrupted" time="0.001" /><testcase classname="tests.test_interrupt_resume.TestInterruptResumeDeterminism" name="test_interrupt_does_not_affect_determinism" time="0.000" /><testcase classname="tests.test_interrupt_resume.TestInterruptSafety" name="test_interrupt_preserves_partial_artifacts" time="0.005" /><testcase classname="tests.test_interrupt_resume.TestInterruptSafety" name="test_interrupt_atomic_state_writes" time="0.002" /><testcase classname="tests.test_io_utils.TestCSVSchemaInference" name="test_infer_csv_schema_does_not_raise_with_mixed_types" time="0.006" /><testcase classname="tests.test_io_utils.TestCSVSchemaInference" name="test_infer_csv_schema_numeric_columns" time="0.004" /><testcase classname="tests.test_io_utils.TestCSVSchemaInference" name="test_infer_csv_schema_id_detection" time="0.003" /><testcase classname="tests.test_io_utils.TestCSVSchemaInference" name="test_infer_csv_schema_empty_column" time="0.002" /><testcase classname="tests.test_io_utils.TestCSVSchemaInference" name="test_infer_csv_schema_file_not_found" time="0.000" /><testcase classname="tests.test_io_utils.TestStableCSVReading" name="test_read_csv_stable_uses_engine_pyarrow_when_available_else_fallback" time="0.005" /><testcase classname="tests.test_io_utils.TestStableCSVReading" name="test_read_csv_stable_resolves_dtypewarning" time="0.007" /><testcase classname="tests.test_io_utils.TestStableCSVReading" name="test_read_csv_stable_with_custom_dtype_map" time="0.003" /><testcase classname="tests.test_io_utils.TestStableCSVReading" name="test_read_csv_stable_file_not_found" time="0.000" /><testcase classname="tests.test_io_utils.TestHelperFunctions" name="test_is_pyarrow_available" time="0.000" /><testcase classname="tests.test_io_utils.TestHelperFunctions" name="test_is_pandas_2_plus" time="0.001" /><testcase classname="tests.test_io_utils.TestHelperFunctions" name="test_is_likely_id_column" time="0.001" /><testcase classname="tests.test_io_utils.TestHelperFunctions" name="test_is_numeric_column" time="0.001" /><testcase classname="tests.test_io_utils.TestHelperFunctions" name="test_has_decimal_points" time="0.001" /><testcase classname="tests.test_io_utils.TestHelperFunctions" name="test_get_csv_engine_preference" time="0.000" /><testcase classname="tests.test_io_utils.TestHelperFunctions" name="test_validate_csv_file" time="0.002" /><testcase classname="tests.test_io_utils.TestHelperFunctions" name="test_cache_clearing" time="0.034" /><testcase classname="tests.test_io_utils" name="test_get_csv_engine_preference" time="0.000" /><testcase classname="tests.test_io_utils" name="test_validate_csv_file" time="0.001"><failure message="AssertionError: assert False is True&#10; +  where False = validate_csv_file('test.csv')">def test_validate_csv_file():
        """Test CSV file validation."""
        # Test with valid file
&gt;       assert validate_csv_file("test.csv") is True
E       AssertionError: assert False is True
E        +  where False = validate_csv_file('test.csv')

tests/test_io_utils.py:350: AssertionError</failure></testcase><testcase classname="tests.test_io_utils.TestSettingsCaching" name="test_settings_caching" time="0.001" /><testcase classname="tests.test_io_utils.TestSettingsCaching" name="test_reload_settings" time="0.071" /><testcase classname="tests.test_io_utils.TestSettingsCaching" name="test_cache_clearing" time="0.029" /><testcase classname="tests.test_mini_dag" name="test_get_last_completed_stage" time="0.004" /><testcase classname="tests.test_mini_dag" name="test_validate_intermediate_files" time="0.001" /><testcase classname="tests.test_mini_dag" name="test_get_smart_resume_stage" time="0.004" /><testcase classname="tests.test_mini_dag" name="test_input_hash_validation" time="0.002" /><testcase classname="tests.test_mini_dag" name="test_force_flag_required_on_hash_mismatch" time="0.001" /><testcase classname="tests.test_mini_dag" name="test_metadata_storage" time="0.001" /><testcase classname="tests.test_mini_dag" name="test_byte_for_byte_invariance" time="0.000" /><testcase classname="tests.test_mini_dag" name="test_auto_resume_decision_logging" time="0.000" /><testcase classname="tests.test_mini_dag" name="test_invariance_resume" time="0.002" /><testcase classname="tests.test_mini_dag" name="test_hash_mismatch_guard" time="0.002" /><testcase classname="tests.test_mini_dag" name="test_missing_artifact_fallback" time="0.002" /><testcase classname="tests.test_mini_dag" name="test_corrupted_state_file" time="0.001" /><testcase classname="tests.test_mini_dag" name="test_resume_force_interaction" time="0.001" /><testcase classname="tests.test_mini_dag" name="test_actual_invariance" time="0.002" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_pipeline_constants_import" time="0.000" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_validate_intermediate_files_basic" time="0.002" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_validate_intermediate_files_complete_pipeline" time="0.003" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_validate_resume_capability_no_previous_run" time="0.001" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_validate_resume_capability_missing_files" time="0.003" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_validate_resume_capability_success" time="0.002" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_validate_state_consistency_valid" time="0.003" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_validate_state_consistency_invalid" time="0.004" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_repair_state_inconsistency" time="0.002" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_get_resume_validation_summary" time="0.002" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_get_smart_resume_stage_enhanced" time="0.003" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_get_smart_resume_stage_with_validation_failure" time="0.002" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_resume_validation_timeout" time="0.011" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_stage_order_consistency" time="0.001" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_error_handling_corrupted_state" time="0.001" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_feature_flag_resume_state_repair" time="0.003" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResume" name="test_logging_enhancements" time="0.002" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResumeIntegration" name="test_full_pipeline_resume_simulation" time="0.006" /><testcase classname="tests.test_mini_dag_resume.TestMiniDAGResumeIntegration" name="test_resume_with_missing_intermediate_files" time="0.003" /><testcase classname="tests.test_mini_dag_resume_contract.TestMiniDAGResumeContract" name="test_resume_from_respects_contract" time="0.001" /><testcase classname="tests.test_mini_dag_resume_contract.TestMiniDAGResumeContract" name="test_resume_stage_validation" time="0.002" /><testcase classname="tests.test_mini_dag_resume_contract.TestMiniDAGResumeContract" name="test_resume_state_persistence" time="0.004" /><testcase classname="tests.test_mini_dag_resume_contract.TestMiniDAGResumeContract" name="test_resume_with_no_previous_run" time="0.001" /><testcase classname="tests.test_mini_dag_resume_contract.TestMiniDAGResumeContract" name="test_resume_stage_ordering" time="0.005" /><testcase classname="tests.test_mini_dag_state_transitions.TestMiniDAGStateTransitions" name="test_state_transitions_with_temp_file" time="0.004" /><testcase classname="tests.test_mini_dag_state_transitions.TestMiniDAGStateTransitions" name="test_resume_from_specific_stage" time="0.004" /><testcase classname="tests.test_mini_dag_state_transitions.TestMiniDAGStateTransitions" name="test_state_file_corruption_handling" time="0.001" /><testcase classname="tests.test_mini_dag_state_transitions.TestMiniDAGStateTransitions" name="test_stage_validation" time="0.002" /><testcase classname="tests.test_no_hardcoding" name="test_no_hardcoded_literals" time="0.002" /><testcase classname="tests.test_no_hardcoding" name="test_path_utils_functions_exist" time="0.000" /><testcase classname="tests.test_no_hardcoding" name="test_schema_utils_constants_exist" time="0.000" /><testcase classname="tests.test_no_hardcoding" name="test_config_structure" time="0.028" /><testcase classname="tests.test_normalize.TestNormalize" name="test_alias_extraction" time="0.001" /><testcase classname="tests.test_normalize.TestNormalize" name="test_basic_normalization" time="0.000" /><testcase classname="tests.test_normalize.TestNormalize" name="test_dataframe_normalization" time="0.002" /><testcase classname="tests.test_normalize.TestNormalize" name="test_edge_cases" time="0.000" /><testcase classname="tests.test_normalize.TestNormalize" name="test_excel_serial_conversion" time="0.000" /><testcase classname="tests.test_normalize.TestNormalize" name="test_multiple_names_detection" time="0.000" /><testcase classname="tests.test_normalize.TestNormalize" name="test_numbered_marker_removal" time="0.000" /><testcase classname="tests.test_normalize.TestNormalize" name="test_numeric_style_unification" time="0.000" /><testcase classname="tests.test_normalize.TestNormalize" name="test_parentheses_detection" time="0.000" /><testcase classname="tests.test_normalize.TestNormalize" name="test_semicolon_detection" time="0.000" /><testcase classname="tests.test_normalize.TestNormalize" name="test_suffix_detection" time="0.000" /><testcase classname="tests.test_normalize.TestNormalize" name="test_suffix_mismatch_detection" time="0.000" /><testcase classname="tests.test_normalize.TestNormalize" name="test_three_variants_same_core" time="0.000" /><testcase classname="tests.test_normalize.TestNormalize" name="test_underscore_normalization" time="0.000" /><testcase classname="tests.test_parallel_execution" name="test_parallel_executor_initialization" time="0.056" /><testcase classname="tests.test_parallel_execution" name="test_should_use_parallel" time="0.027" /><testcase classname="tests.test_parallel_execution" name="test_deterministic_execution" time="0.054" /><testcase classname="tests.test_parallel_execution" name="test_worker_count_variations" time="0.081" /><testcase classname="tests.test_parallel_execution" name="test_backend_comparison" time="0.055" /><testcase classname="tests.test_parallel_execution" name="test_chunked_execution" time="0.028" /><testcase classname="tests.test_parallel_execution" name="test_ensure_deterministic_order" time="0.000" /><testcase classname="tests.test_parallel_execution" name="test_resource_monitoring" time="0.000" /><testcase classname="tests.test_parallel_execution" name="test_error_handling" time="0.028" /><testcase classname="tests.test_parallel_execution" name="test_small_input_guard" time="0.027" /><testcase classname="tests.test_parallel_execution" name="test_memory_guard" time="0.000" /><testcase classname="tests.test_parallel_utils.TestLokyAvailability" name="test_is_loky_available_returns_bool" time="0.000" /><testcase classname="tests.test_parallel_utils.TestLokyAvailability" name="test_is_loky_available_when_joblib_unavailable" time="0.000" /><testcase classname="tests.test_parallel_utils.TestLokyAvailability" name="test_is_loky_available_when_loky_works" time="0.000" /><testcase classname="tests.test_parallel_utils.TestLokyAvailability" name="test_is_loky_available_when_loky_fails" time="0.000" /><testcase classname="tests.test_parallel_utils.TestBackendSelection" name="test_select_backend_when_joblib_unavailable" time="0.000" /><testcase classname="tests.test_parallel_utils.TestBackendSelection" name="test_select_backend_requested_threading" time="0.000" /><testcase classname="tests.test_parallel_utils.TestBackendSelection" name="test_select_backend_requested_loky_but_unavailable_falls_back_to_threading" time="0.000" /><testcase classname="tests.test_parallel_utils.TestBackendSelection" name="test_select_backend_requested_loky_and_available" time="0.000" /><testcase classname="tests.test_parallel_utils.TestBackendSelection" name="test_select_backend_default_when_loky_available" time="0.000" /><testcase classname="tests.test_parallel_utils.TestBackendSelection" name="test_select_backend_default_when_loky_unavailable" time="0.000" /><testcase classname="tests.test_parallel_utils.TestParallelExecutor" name="test_parallel_executor_initialization" time="0.000" /><testcase classname="tests.test_parallel_utils.TestParallelExecutor" name="test_parallel_executor_when_joblib_unavailable" time="0.000" /><testcase classname="tests.test_parallel_utils.TestParallelExecutor" name="test_parallel_executor_with_stop_flag" time="0.001" /><testcase classname="tests.test_parallel_utils.TestParallelExecutor" name="test_parallel_executor_default_stop_flag" time="0.000" /><testcase classname="tests.test_parallel_utils.TestParallelExecutor" name="test_execute_with_stop_flag" time="0.000" /><testcase classname="tests.test_parallel_utils.TestParallelExecutor" name="test_execute_chunked_with_stop_flag" time="0.000" /><testcase classname="tests.test_parallel_utils.TestParallelExecutorChunking" name="test_balanced_chunking_large_input" time="0.024" /><testcase classname="tests.test_parallel_utils.TestParallelExecutorChunking" name="test_sequential_fallback_small_input" time="0.000" /><testcase classname="tests.test_parallel_utils.TestCreateParallelExecutor" name="test_create_parallel_executor" time="0.001" /><testcase classname="tests.test_perf_utils" name="test_track_memory_peak" time="0.001"><failure message="assert &quot;Memory peak at 'test_stage'&quot; in ''&#10; +  where '' = &lt;_pytest.logging.LogCaptureFixture object at 0x1213742c0&gt;.text">caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x1213742c0&gt;

    def test_track_memory_peak(caplog: pytest.LogCaptureFixture) -&gt; None:
        """Test memory peak tracking context manager."""
        # Set up logging to capture messages
        caplog.set_level(logging.INFO)
        logger = logging.getLogger("test")
    
        with track_memory_peak("test_stage", logger):
            # Simulate some memory usage
            pass
    
        # Should log memory peak
&gt;       assert "Memory peak at 'test_stage'" in caplog.text
E       assert "Memory peak at 'test_stage'" in ''
E        +  where '' = &lt;_pytest.logging.LogCaptureFixture object at 0x1213742c0&gt;.text

tests/test_perf_utils.py:31: AssertionError</failure></testcase><testcase classname="tests.test_perf_utils" name="test_time_stage" time="0.013"><failure message="assert &quot;Stage 'test_stage' completed in&quot; in 'INFO     test:perf_utils.py:249 [stage:start] test_stage\nINFO     test:perf_utils.py:254 [stage:end] test_stage (0.01s)\n'&#10; +  where 'INFO     test:perf_utils.py:249 [stage:start] test_stage\nINFO     test:perf_utils.py:254 [stage:end] test_stage (0.01s)\n' = &lt;_pytest.logging.LogCaptureFixture object at 0x12134a630&gt;.text">caplog = &lt;_pytest.logging.LogCaptureFixture object at 0x12134a630&gt;

    def test_time_stage(caplog: pytest.LogCaptureFixture) -&gt; None:
        """Test stage timing context manager."""
        # Set up logging to capture messages
        caplog.set_level(logging.INFO)
        logger = logging.getLogger("test")
    
        with time_stage("test_stage", logger):
            # Simulate some work
            time.sleep(0.01)
    
        # Should log timing
&gt;       assert "Stage 'test_stage' completed in" in caplog.text
E       assert "Stage 'test_stage' completed in" in 'INFO     test:perf_utils.py:249 [stage:start] test_stage\nINFO     test:perf_utils.py:254 [stage:end] test_stage (0.01s)\n'
E        +  where 'INFO     test:perf_utils.py:249 [stage:start] test_stage\nINFO     test:perf_utils.py:254 [stage:end] test_stage (0.01s)\n' = &lt;_pytest.logging.LogCaptureFixture object at 0x12134a630&gt;.text

tests/test_perf_utils.py:45: AssertionError</failure></testcase><testcase classname="tests.test_perf_utils" name="test_log_performance_summary" time="0.001" /><testcase classname="tests.test_perf_utils" name="test_context_managers_exception_handling" time="0.000" /><testcase classname="tests.test_readonly_safety.TestReadOnlySafety" name="test_no_destructive_functions_in_code" time="0.491"><failure message="AssertionError: Found potentially destructive functions in production code:&#10;  app/components/maintenance.py:213:preview_delete_runs&#10;  app/components/maintenance.py:233:delete_runs&#10;  scripts/run_modes_benchmark.py:347:shutil.rmtree&#10;  All destructive operations must be gated behind Phase-1 fuses.&#10;assert 3 == 0&#10; +  where 3 = len({'app/components/maintenance.py:213:preview_delete_runs', 'app/components/maintenance.py:233:delete_runs', 'scripts/run_modes_benchmark.py:347:shutil.rmtree'})">self = &lt;tests.test_readonly_safety.TestReadOnlySafety object at 0x1205de330&gt;

    def test_no_destructive_functions_in_code(self) -&gt; None:
        """Test that no destructive functions are called in the codebase."""
        destructive_functions = find_destructive_functions()
    
        # Filter out legitimate uses (like in tests or cleanup tools)
        legitimate_uses = set()
        for func in destructive_functions:
            file_path = func.split(":")[0]
            if any(legit in file_path for legit in ["test_", "cleanup_", "tools/"]):
                legitimate_uses.add(func)
    
        # Remove legitimate uses from the set
        problematic_functions = destructive_functions - legitimate_uses
    
&gt;       assert len(problematic_functions) == 0, (
            f"Found potentially destructive functions in production code:\n"
            f"{chr(10).join(sorted(problematic_functions))}\n"
            f"All destructive operations must be gated behind Phase-1 fuses."
        )
E       AssertionError: Found potentially destructive functions in production code:
E         app/components/maintenance.py:213:preview_delete_runs
E         app/components/maintenance.py:233:delete_runs
E         scripts/run_modes_benchmark.py:347:shutil.rmtree
E         All destructive operations must be gated behind Phase-1 fuses.
E       assert 3 == 0
E        +  where 3 = len({'app/components/maintenance.py:213:preview_delete_runs', 'app/components/maintenance.py:233:delete_runs', 'scripts/run_modes_benchmark.py:347:shutil.rmtree'})

tests/test_readonly_safety.py:231: AssertionError</failure></testcase><testcase classname="tests.test_readonly_safety.TestReadOnlySafety" name="test_no_direct_run_index_deletions" time="0.436" /><testcase classname="tests.test_readonly_safety.TestReadOnlySafety" name="test_maintenance_ui_shows_readonly_copy" time="0.001"><failure message="AssertionError: Maintenance UI must show: 'Run deletion functionality will be implemented in a future phase.'&#10;assert False&#10; +  where False = check_maintenance_ui_copy()">self = &lt;tests.test_readonly_safety.TestReadOnlySafety object at 0x1205de630&gt;

    def test_maintenance_ui_shows_readonly_copy(self) -&gt; None:
        """Test that maintenance UI shows the correct read-only message."""
&gt;       assert (
            check_maintenance_ui_copy()
        ), "Maintenance UI must show: 'Run deletion functionality will be implemented in a future phase.'"
E       AssertionError: Maintenance UI must show: 'Run deletion functionality will be implemented in a future phase.'
E       assert False
E        +  where False = check_maintenance_ui_copy()

tests/test_readonly_safety.py:259: AssertionError</failure></testcase><testcase classname="tests.test_readonly_safety.TestReadOnlySafety" name="test_maintenance_rendered_in_sidebar" time="0.001"><failure message="AssertionError: Maintenance component must be rendered in sidebar using st.sidebar.subheader&#10;assert False&#10; +  where False = check_sidebar_placement()">self = &lt;tests.test_readonly_safety.TestReadOnlySafety object at 0x1205de7b0&gt;

    def test_maintenance_rendered_in_sidebar(self) -&gt; None:
        """Test that maintenance is rendered in sidebar context."""
&gt;       assert (
            check_sidebar_placement()
        ), "Maintenance component must be rendered in sidebar using st.sidebar.subheader"
E       AssertionError: Maintenance component must be rendered in sidebar using st.sidebar.subheader
E       assert False
E        +  where False = check_sidebar_placement()

tests/test_readonly_safety.py:265: AssertionError</failure></testcase><testcase classname="tests.test_readonly_safety.TestReadOnlySafety" name="test_phase_1_fuse_not_enabled" time="0.001" /><testcase classname="tests.test_readonly_safety.TestReadOnlySafety" name="test_no_destructive_ui_buttons" time="0.002" /><testcase classname="tests.test_resource_monitor" name="test_get_system_info" time="0.000" /><testcase classname="tests.test_resource_monitor" name="test_estimate_memory_per_worker" time="0.000" /><testcase classname="tests.test_resource_monitor" name="test_calculate_optimal_workers_mock" time="0.001" /><testcase classname="tests.test_resource_monitor" name="test_calculate_optimal_workers_no_psutil" time="0.000" /><testcase classname="tests.test_resource_monitor" name="test_check_disk_space" time="0.001" /><testcase classname="tests.test_resource_monitor" name="test_check_disk_space_no_psutil" time="0.000" /><testcase classname="tests.test_resource_monitor" name="test_get_memory_usage" time="0.001" /><testcase classname="tests.test_resource_monitor" name="test_get_memory_usage_no_psutil" time="0.000" /><testcase classname="tests.test_resource_monitor" name="test_log_resource_summary" time="0.000" /><testcase classname="tests.test_resource_monitor" name="test_monitor_parallel_execution" time="0.000" /><testcase classname="tests.test_resource_monitor" name="test_memory_cap_guard" time="0.001" /><testcase classname="tests.test_resource_monitor" name="test_worker_count_limits" time="0.000" /><testcase classname="tests.test_resource_monitor" name="test_error_handling" time="0.001" /><testcase classname="tests.test_resource_monitor" name="test_memory_percentage_calculation" time="0.000" /><testcase classname="tests.test_run_maintenance_ui" name="test_checkbox_confirmation_logic" time="0.000" /><testcase classname="tests.test_run_maintenance_ui" name="test_preview_payload_rendering" time="0.000" /><testcase classname="tests.test_run_maintenance_ui" name="test_preview_payload_edge_cases" time="0.000" /><testcase classname="tests.test_run_maintenance_ui" name="test_quick_action_session_state" time="0.000" /><testcase classname="tests.test_schema_apply" name="test_invert_mapping" time="0.000" /><testcase classname="tests.test_schema_apply" name="test_apply_canonical_rename_success" time="0.001" /><testcase classname="tests.test_schema_apply" name="test_apply_canonical_rename_missing_required_column" time="0.001" /><testcase classname="tests.test_schema_apply" name="test_apply_canonical_rename_partial_mapping" time="0.001" /><testcase classname="tests.test_schema_casing.TestSchemaCasing" name="test_schema_casing_disposition_lowercase" time="0.001"><skipped type="pytest.skip" message="Could not test schema casing: [Errno 2] No such file or directory: 'data/processed/latest/group_stats.parquet'">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_schema_casing.py:47: Could not test schema casing: [Errno 2] No such file or directory: 'data/processed/latest/group_stats.parquet'</skipped></testcase><testcase classname="tests.test_schema_casing.TestSchemaCasing" name="test_schema_casing_review_ready_lowercase" time="0.001"><skipped type="pytest.skip" message="Could not test review_ready schema casing: [Errno 2] No such file or directory: 'data/processed/latest/review_ready.parquet'">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_schema_casing.py:66: Could not test review_ready schema casing: [Errno 2] No such file or directory: 'data/processed/latest/review_ready.parquet'</skipped></testcase><testcase classname="tests.test_schema_casing.TestSchemaCasing" name="test_schema_casing_group_details_lowercase" time="0.000"><skipped type="pytest.skip" message="Could not test group_details schema casing: [Errno 2] No such file or directory: 'data/processed/latest/group_details.parquet'">/Users/joe.j/Documents/dev/salesforce/apps/company_junction/tests/test_schema_casing.py:81: Could not test group_details schema casing: [Errno 2] No such file or directory: 'data/processed/latest/group_details.parquet'</skipped></testcase><testcase classname="tests.test_schema_casing.TestSchemaCasing" name="test_schema_casing_backend_specific_files" time="0.000" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_resolve_schema_cli_overrides" time="0.001" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_resolve_schema_template_matching" time="0.001" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_resolve_schema_synonym_matching" time="0.001" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_resolve_schema_heuristic_fallback" time="0.002" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_resolve_schema_missing_required_column" time="0.002" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_resolve_schema_case_insensitive_matching" time="0.001" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_apply_cli_overrides" time="0.001" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_apply_cli_overrides_missing_column" time="0.000" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_match_filename_template" time="0.000" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_match_filename_template_no_match" time="0.001" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_match_filename_template_invalid_regex" time="0.001" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_match_synonyms" time="0.000" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_build_mapping_from_aliases" time="0.000" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_apply_heuristics" time="0.001" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_find_best_similarity_match" time="0.000" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_find_id_columns" time="0.001" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_find_date_columns" time="0.001" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_validate_required_columns" time="0.000" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_save_schema_mapping" time="0.001" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_load_schema_mapping" time="0.000" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_resolve_schema_with_empty_settings" time="0.002" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_resolve_schema_with_none_settings" time="0.002" /><testcase classname="tests.test_schema_resolver.TestSchemaResolver" name="test_resolve_schema_deterministic_ordering" time="0.001" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_score_clamp_upper_bound" time="0.028" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_score_clamp_lower_bound" time="0.000" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_score_rounding_behavior" time="0.000" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_score_rounding_edge_cases" time="0.000" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_component_score_bounds" time="0.000" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_penalty_application_bounds" time="0.000" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_base_score_calculation" time="0.000" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_penalty_subtraction_accuracy" time="0.000" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_score_precision" time="0.000" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_extreme_penalty_values" time="0.000" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_zero_penalty_values" time="0.000" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_negative_penalty_values" time="0.000" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_combined_penalty_bounds" time="0.000" /><testcase classname="tests.test_scoring_bounds.TestScoringBounds" name="test_edge_case_score_boundaries" time="0.000" /><testcase classname="tests.test_scoring_bulk_gate.TestScoringBulkGate" name="test_bulk_gate_cutoff_behavior" time="0.002" /><testcase classname="tests.test_scoring_bulk_gate.TestScoringBulkGate" name="test_bulk_gate_filtering_logic" time="0.001" /><testcase classname="tests.test_scoring_bulk_gate.TestScoringBulkGate" name="test_bulk_gate_performance" time="0.003" /><testcase classname="tests.test_scoring_bulk_gate.TestScoringBulkGate" name="test_bulk_gate_empty_results" time="0.002" /><testcase classname="tests.test_scoring_bulk_gate.TestScoringBulkGate" name="test_bulk_gate_all_results" time="0.002" /><testcase classname="tests.test_scoring_bulk_parity.TestScoringBulkParity" name="test_parity_of_scores_components" time="0.002" /><testcase classname="tests.test_scoring_bulk_parity.TestScoringBulkParity" name="test_gate_correctness_below_cutoff" time="0.001" /><testcase classname="tests.test_scoring_bulk_parity.TestScoringBulkParity" name="test_gate_correctness_above_cutoff" time="0.001" /><testcase classname="tests.test_scoring_bulk_parity.TestScoringBulkParity" name="test_suffix_defaulting_non_mutation" time="0.004" /><testcase classname="tests.test_scoring_bulk_parity.TestScoringBulkParity" name="test_order_stability_sequential" time="0.002" /><testcase classname="tests.test_scoring_bulk_parity.TestScoringBulkParity" name="test_gate_logging_smoke_check" time="0.002" /><testcase classname="tests.test_scoring_bulk_parity.TestScoringBulkParity" name="test_empty_candidate_pairs" time="0.001" /><testcase classname="tests.test_scoring_bulk_parity.TestScoringBulkParity" name="test_single_candidate_pair" time="0.002" /><testcase classname="tests.test_scoring_bulk_parity.TestScoringBulkParity" name="test_configurable_gate_cutoff" time="0.001" /><testcase classname="tests.test_scoring_components.TestScoringComponents" name="test_token_sort_ratio_sensitivity" time="0.000" /><testcase classname="tests.test_scoring_components.TestScoringComponents" name="test_token_sort_ratio_vs_set_difference" time="0.000" /><testcase classname="tests.test_scoring_components.TestScoringComponents" name="test_token_set_ratio_resilience" time="0.000" /><testcase classname="tests.test_scoring_components.TestScoringComponents" name="test_token_set_ratio_weak_token_handling" time="0.000" /><testcase classname="tests.test_scoring_components.TestScoringComponents" name="test_jaccard_enhanced_tokens" time="0.000" /><testcase classname="tests.test_scoring_components.TestScoringComponents" name="test_jaccard_plural_singular_mapping" time="0.000" /><testcase classname="tests.test_scoring_components.TestScoringComponents" name="test_jaccard_canonical_retail_terms" time="0.000" /><testcase classname="tests.test_scoring_components.TestScoringComponents" name="test_jaccard_weak_token_removal" time="0.000" /><testcase classname="tests.test_scoring_components.TestScoringComponents" name="test_jaccard_empty_tokens" time="0.000" /><testcase classname="tests.test_scoring_components.TestScoringComponents" name="test_enhanced_normalization_fallback" time="0.001" /><testcase classname="tests.test_scoring_config_defaults.TestScoringConfigDefaults" name="test_penalty_removal_no_score_drop" time="0.002" /><testcase classname="tests.test_scoring_config_defaults.TestScoringConfigDefaults" name="test_gate_cutoff_behavior_change" time="0.002" /><testcase classname="tests.test_scoring_config_defaults.TestScoringConfigDefaults" name="test_default_penalty_values" time="0.000" /><testcase classname="tests.test_scoring_config_defaults.TestScoringConfigDefaults" name="test_default_gate_cutoff" time="0.000" /><testcase classname="tests.test_scoring_config_defaults.TestScoringConfigDefaults" name="test_default_bulk_cdist_setting" time="0.000" /><testcase classname="tests.test_scoring_config_defaults.TestScoringConfigDefaults" name="test_config_missing_values_defaults" time="0.002" /><testcase classname="tests.test_scoring_config_defaults.TestScoringConfigDefaults" name="test_config_empty_values_defaults" time="0.002" /><testcase classname="tests.test_scoring_config_defaults.TestScoringConfigDefaults" name="test_config_none_values_defaults" time="0.003" /><testcase classname="tests.test_scoring_config_defaults.TestScoringConfigDefaults" name="test_config_override_defaults" time="0.002" /><testcase classname="tests.test_scoring_config_defaults.TestScoringConfigDefaults" name="test_config_validation_defaults" time="0.001" /><testcase classname="tests.test_scoring_config_defaults.TestScoringConfigDefaults" name="test_config_type_coercion" time="0.001" /><testcase classname="tests.test_scoring_config_defaults.TestScoringConfigDefaults" name="test_config_nested_defaults" time="0.001" /><testcase classname="tests.test_scoring_config_defaults.TestScoringConfigDefaults" name="test_penalty_values_from_config" time="0.001" /><testcase classname="tests.test_scoring_config_toggles.TestScoringConfigToggles" name="test_medium_threshold_filtering" time="0.000" /><testcase classname="tests.test_scoring_config_toggles.TestScoringConfigToggles" name="test_penalty_value_changes" time="0.000" /><testcase classname="tests.test_scoring_config_toggles.TestScoringConfigToggles" name="test_penalty_disabling" time="0.000" /><testcase classname="tests.test_scoring_config_toggles.TestScoringConfigToggles" name="test_normalization_weak_tokens_toggle" time="0.000" /><testcase classname="tests.test_scoring_config_toggles.TestScoringConfigToggles" name="test_normalization_plural_map_toggle" time="0.000" /><testcase classname="tests.test_scoring_config_toggles.TestScoringConfigToggles" name="test_normalization_canonical_terms_toggle" time="0.000" /><testcase classname="tests.test_scoring_config_toggles.TestScoringConfigToggles" name="test_gate_cutoff_configuration" time="0.000" /><testcase classname="tests.test_scoring_config_toggles.TestScoringConfigToggles" name="test_bulk_cdist_toggle" time="0.000" /><testcase classname="tests.test_scoring_config_toggles.TestScoringConfigToggles" name="test_parallel_workers_configuration" time="0.000" /><testcase classname="tests.test_scoring_config_toggles.TestScoringConfigToggles" name="test_config_validation" time="0.000" /><testcase classname="tests.test_scoring_config_toggles.TestScoringConfigToggles" name="test_config_defaults" time="0.000" /><testcase classname="tests.test_scoring_config_toggles.TestScoringConfigToggles" name="test_config_override_behavior" time="0.000" /><testcase classname="tests.test_scoring_config_toggles.TestScoringConfigToggles" name="test_config_immutability" time="0.000" /><testcase classname="tests.test_scoring_contracts.TestScoringContracts" name="test_no_dataframe_mutation" time="0.003" /><testcase classname="tests.test_scoring_contracts.TestScoringContracts" name="test_string_dtype_enforcement" time="0.001" /><testcase classname="tests.test_scoring_contracts.TestScoringContracts" name="test_sort_order_contract_documentation" time="0.001" /><testcase classname="tests.test_scoring_contracts.TestScoringContracts" name="test_deterministic_outputs" time="0.001" /><testcase classname="tests.test_scoring_contracts.TestScoringContracts" name="test_output_column_structure" time="0.002" /><testcase classname="tests.test_scoring_contracts.TestScoringContracts" name="test_output_data_types" time="0.002" /><testcase classname="tests.test_scoring_contracts.TestScoringContracts" name="test_empty_input_handling" time="0.001" /><testcase classname="tests.test_scoring_contracts.TestScoringContracts" name="test_output_consistency_bulk_parallel" time="0.002" /><testcase classname="tests.test_scoring_contracts.TestScoringContracts" name="test_score_bounds_contract" time="0.001" /><testcase classname="tests.test_scoring_contracts.TestScoringContracts" name="test_penalty_flags_contract" time="0.001" /><testcase classname="tests.test_scoring_contracts.TestScoringContracts" name="test_component_scores_contract" time="0.002" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_jaccard_empty_tokens_returns_zero" time="0.001" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_empty_candidate_list_empty_dataframe" time="0.002" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_empty_candidate_list_no_mutation" time="0.003" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_empty_candidate_list_correct_columns" time="0.001" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_none_inputs_handling" time="0.002" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_empty_string_inputs_handling" time="0.000" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_whitespace_only_inputs_handling" time="0.000" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_single_character_inputs_handling" time="0.000" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_very_long_inputs_handling" time="0.010" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_special_character_only_inputs_handling" time="0.000" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_numeric_only_inputs_handling" time="0.000" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_mixed_type_inputs_handling" time="0.000" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_unicode_inputs_handling" time="0.000" /><testcase classname="tests.test_scoring_degenerate.TestScoringDegenerate" name="test_edge_case_combinations" time="0.000" /><testcase classname="tests.test_scoring_enhanced_fallback.TestScoringEnhancedFallback" name="test_normalize_import_failure_fallback" time="0.000" /><testcase classname="tests.test_scoring_enhanced_fallback.TestScoringEnhancedFallback" name="test_enhance_name_core_failure_fallback" time="0.000" /><testcase classname="tests.test_scoring_enhanced_fallback.TestScoringEnhancedFallback" name="test_get_enhanced_tokens_failure_fallback" time="0.000" /><testcase classname="tests.test_scoring_enhanced_fallback.TestScoringEnhancedFallback" name="test_penalties_apply_during_fallback" time="0.000" /><testcase classname="tests.test_scoring_enhanced_fallback.TestScoringEnhancedFallback" name="test_no_exceptions_leak_fallback" time="0.001" /><testcase classname="tests.test_scoring_enhanced_fallback.TestScoringEnhancedFallback" name="test_fallback_score_consistency" time="0.001" /><testcase classname="tests.test_scoring_enhanced_fallback.TestScoringEnhancedFallback" name="test_fallback_performance" time="0.000" /><testcase classname="tests.test_scoring_enhanced_fallback.TestScoringEnhancedFallback" name="test_fallback_logging" time="0.000" /><testcase classname="tests.test_scoring_enhanced_fallback.TestScoringEnhancedFallback" name="test_fallback_graceful_degradation" time="0.000" /><testcase classname="tests.test_scoring_enhanced_fallback.TestScoringEnhancedFallback" name="test_fallback_error_recovery" time="0.001" /><testcase classname="tests.test_scoring_enhanced_fallback.TestScoringEnhancedFallback" name="test_fallback_configuration_handling" time="0.000" /><testcase classname="tests.test_scoring_enhanced_fallback.TestScoringEnhancedFallback" name="test_fallback_determinism" time="0.000" /><testcase classname="tests.test_scoring_logging.TestScoringLogging" name="test_bulk_gate_logging_exists" time="0.002" /><testcase classname="tests.test_scoring_logging.TestScoringLogging" name="test_bulk_gate_logging_empty_candidates" time="0.002" /><testcase classname="tests.test_scoring_logging.TestScoringLogging" name="test_bulk_gate_logging_consistency" time="0.002" /><testcase classname="tests.test_scoring_logging.TestScoringLogging" name="test_bulk_gate_logging_performance" time="0.002" /><testcase classname="tests.test_scoring_logging.TestScoringLogging" name="test_bulk_gate_logging_documentation" time="0.001" /><testcase classname="tests.test_scoring_logging_bulk_gate.TestScoringLoggingBulkGate" name="test_bulk_gate_info_log_format" time="0.000" /><testcase classname="tests.test_scoring_logging_bulk_gate.TestScoringLoggingBulkGate" name="test_bulk_gate_log_level" time="0.000" /><testcase classname="tests.test_scoring_logging_bulk_gate.TestScoringLoggingBulkGate" name="test_bulk_gate_log_content" time="0.000" /><testcase classname="tests.test_scoring_logging_bulk_gate.TestScoringLoggingBulkGate" name="test_bulk_gate_log_timing" time="0.000" /><testcase classname="tests.test_scoring_logging_bulk_gate.TestScoringLoggingBulkGate" name="test_bulk_gate_log_context" time="0.000" /><testcase classname="tests.test_scoring_logging_bulk_gate.TestScoringLoggingBulkGate" name="test_bulk_gate_log_performance" time="0.000" /><testcase classname="tests.test_scoring_logging_bulk_gate.TestScoringLoggingBulkGate" name="test_bulk_gate_log_thread_safety" time="0.000" /><testcase classname="tests.test_scoring_logging_bulk_gate.TestScoringLoggingBulkGate" name="test_bulk_gate_log_memory_usage" time="0.000" /><testcase classname="tests.test_scoring_logging_bulk_gate.TestScoringLoggingBulkGate" name="test_bulk_gate_log_error_handling" time="0.000" /><testcase classname="tests.test_scoring_logging_bulk_gate.TestScoringLoggingBulkGate" name="test_bulk_gate_log_configuration" time="0.000" /><testcase classname="tests.test_scoring_logging_bulk_gate.TestScoringLoggingBulkGate" name="test_bulk_gate_log_consistency" time="0.000" /><testcase classname="tests.test_scoring_logging_bulk_gate.TestScoringLoggingBulkGate" name="test_bulk_gate_log_validation" time="0.000" /><testcase classname="tests.test_scoring_output_persistence.TestScoringOutputPersistence" name="test_output_format_consistency" time="0.001" /><testcase classname="tests.test_scoring_output_persistence.TestScoringOutputPersistence" name="test_output_data_types" time="0.001" /><testcase classname="tests.test_scoring_output_persistence.TestScoringOutputPersistence" name="test_output_structure" time="0.001" /><testcase classname="tests.test_scoring_output_persistence.TestScoringOutputPersistence" name="test_output_consistency_bulk_parallel" time="0.001" /><testcase classname="tests.test_scoring_output_persistence.TestScoringOutputPersistence" name="test_output_empty_input" time="0.001" /><testcase classname="tests.test_scoring_output_persistence.TestScoringOutputPersistence" name="test_output_determinism" time="0.001" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_suffix_mismatch_penalty_exact" time="0.000" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_suffix_mismatch_penalty_values" time="0.000" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_numeric_style_mismatch_penalty" time="0.000" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_numeric_style_mismatch_digit_patterns" time="0.000" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_numeric_style_match_same_patterns" time="0.000" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_punctuation_mismatch_penalty" time="0.000" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_punctuation_mismatch_apostrophes" time="0.000" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_punctuation_variants_en_dash" time="0.000" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_punctuation_variants_smart_quotes_unit_path" time="0.000" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_penalty_boolean_flags" time="0.000" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_penalty_config_toggles" time="0.000" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_multiple_penalties_combined" time="0.000" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_penalty_edge_cases_zero_values" time="0.000" /><testcase classname="tests.test_scoring_penalties.TestScoringPenalties" name="test_punctuation_penalty_production_flow" time="0.002" /><testcase classname="tests.test_scoring_persistence.TestScoringPersistence" name="test_interim_dir_parquet_schema" time="0.000" /><testcase classname="tests.test_scoring_persistence.TestScoringPersistence" name="test_parquet_file_creation" time="0.000" /><testcase classname="tests.test_scoring_persistence.TestScoringPersistence" name="test_parquet_schema_validation" time="0.000" /><testcase classname="tests.test_scoring_persistence.TestScoringPersistence" name="test_parquet_data_integrity" time="0.000" /><testcase classname="tests.test_scoring_persistence.TestScoringPersistence" name="test_parquet_file_permissions" time="0.000" /><testcase classname="tests.test_scoring_persistence.TestScoringPersistence" name="test_parquet_file_cleanup" time="0.000" /><testcase classname="tests.test_scoring_persistence.TestScoringPersistence" name="test_interim_dir_creation" time="0.000" /><testcase classname="tests.test_scoring_persistence.TestScoringPersistence" name="test_interim_dir_permissions" time="0.000" /><testcase classname="tests.test_scoring_persistence.TestScoringPersistence" name="test_parquet_compression" time="0.000" /><testcase classname="tests.test_scoring_persistence.TestScoringPersistence" name="test_parquet_metadata" time="0.000" /><testcase classname="tests.test_scoring_persistence.TestScoringPersistence" name="test_parquet_readability" time="0.000" /><testcase classname="tests.test_scoring_persistence.TestScoringPersistence" name="test_parquet_performance" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_whitespace_variants_leading_trailing" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_whitespace_variants_multiple_spaces" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_whitespace_variants_tabs_newlines" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_empty_names_handling" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_short_names_handling" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_missing_suffix_class_defaulting" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_unicode_smart_quotes" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_unicode_en_dash_vs_hyphen" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_unicode_em_dash_vs_hyphen" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_unicode_curly_quotes" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_unicode_accents" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_unicode_special_characters" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_none_input_handling" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_numeric_only_names" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_special_character_only_names" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_very_long_names" time="0.000" /><testcase classname="tests.test_scoring_robustness.TestScoringRobustness" name="test_mixed_unicode_normalization" time="0.002" /><testcase classname="tests.test_scoring_threshold_sort.TestScoringThresholdSort" name="test_medium_threshold_filters_below_cutoff" time="0.002" /><testcase classname="tests.test_scoring_threshold_sort.TestScoringThresholdSort" name="test_gate_cutoff_boundary_behavior" time="0.001" /><testcase classname="tests.test_scoring_threshold_sort.TestScoringThresholdSort" name="test_gate_cutoff_configuration" time="0.002" /><testcase classname="tests.test_scoring_threshold_sort.TestScoringThresholdSort" name="test_stable_sort_contract_documentation" time="0.002" /><testcase classname="tests.test_scoring_threshold_sort.TestScoringThresholdSort" name="test_stable_sort_contract_specification" time="0.002" /><testcase classname="tests.test_scoring_threshold_sort.TestScoringThresholdSort" name="test_sort_determinism_contract" time="0.001" /><testcase classname="tests.test_scoring_threshold_sort.TestScoringThresholdSort" name="test_sort_stability_contract" time="0.002" /><testcase classname="tests.test_scoring_threshold_sort.TestScoringThresholdSort" name="test_threshold_edge_cases" time="0.002" /><testcase classname="tests.test_scoring_threshold_sort.TestScoringThresholdSort" name="test_sort_edge_cases" time="0.002" /><testcase classname="tests.test_scoring_threshold_sort.TestScoringThresholdSort" name="test_threshold_sort_integration" time="0.002" /><testcase classname="tests.test_similarity.TestSimilarity" name="test_candidate_pair_generation" time="0.004" /><testcase classname="tests.test_similarity.TestSimilarity" name="test_inc_vs_inc_high_score" time="0.003" /><testcase classname="tests.test_similarity.TestSimilarity" name="test_inc_vs_llc_verification_needed" time="0.003" /><testcase classname="tests.test_similarity.TestSimilarity" name="test_save_load_candidate_pairs" time="0.009" /><testcase classname="tests.test_similarity_extend_regression" name="test_list_extend_misuse_regression" time="0.000" /><testcase classname="tests.test_similarity_fix.TestSimilarityFix" name="test_99_cents_grouping_with_matching_suffixes" time="0.000" /><testcase classname="tests.test_similarity_fix.TestSimilarityFix" name="test_99_cents_grouping_with_different_suffixes" time="0.000" /><testcase classname="tests.test_similarity_fix.TestSimilarityFix" name="test_7_eleven_variants_remain_high" time="0.000" /><testcase classname="tests.test_similarity_fix.TestSimilarityFix" name="test_enhanced_normalization_features" time="0.000" /><testcase classname="tests.test_similarity_fix.TestSimilarityFix" name="test_soft_ban_denylist_still_yields_candidates" time="0.028" /><testcase classname="tests.test_similarity_fix.TestSimilarityFix" name="test_configuration_keys_exist" time="0.000" /><testcase classname="tests.test_similarity_fix.TestSimilarityFix" name="test_edge_cases" time="0.000" /><testcase classname="tests.test_similarity_fixes.TestSimilarityFixes" name="test_lowercased_block_keys_hit_allowlist" time="0.002" /><testcase classname="tests.test_similarity_fixes.TestSimilarityFixes" name="test_allowlisted_bigrams_generate_pairs" time="0.002" /><testcase classname="tests.test_similarity_fixes.TestSimilarityFixes" name="test_duplicate_pairs_are_deduped" time="0.001" /><testcase classname="tests.test_similarity_fixes.TestSimilarityFixes" name="test_diagnostics_write_to_correct_directory" time="0.002" /><testcase classname="tests.test_similarity_fixes.TestSimilarityFixes" name="test_bulk_gate_no_cdist_shape_error" time="0.003" /><testcase classname="tests.test_similarity_fixes.TestSimilarityFixes" name="test_punctuation_penalty_is_applied" time="0.000" /><testcase classname="tests.test_similarity_header_list_regression" name="test_header_list_raises_typeerror" time="0.000"><failure message="AttributeError: &lt;module 'src.similarity' from '/Users/joe.j/Documents/dev/salesforce/apps/company_junction/src/similarity/__init__.py'&gt; has no attribute '_compute_similarity_scores_parallel'">monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x124a5f020&gt;

    def test_header_list_raises_typeerror(monkeypatch: pytest.MonkeyPatch) -&gt; None:
        def fake_parallel(*args, **kwargs):
            return ["id_a", "id_b", "score", "ratio_name", "ratio_set"]
    
&gt;       monkeypatch.setattr(sim, "_compute_similarity_scores_parallel", fake_parallel)
E       AttributeError: &lt;module 'src.similarity' from '/Users/joe.j/Documents/dev/salesforce/apps/company_junction/src/similarity/__init__.py'&gt; has no attribute '_compute_similarity_scores_parallel'

tests/test_similarity_header_list_regression.py:11: AttributeError</failure></testcase><testcase classname="tests.test_similarity_improvements.TestSimilarityImprovements" name="test_lowercased_config_tokens_hit_allowlist" time="0.001" /><testcase classname="tests.test_similarity_improvements.TestSimilarityImprovements" name="test_allowlisted_token_sharding_safety_rail" time="0.002" /><testcase classname="tests.test_similarity_improvements.TestSimilarityImprovements" name="test_allowlisted_bigram_sharding_safety_rail" time="0.003" /><testcase classname="tests.test_similarity_improvements.TestSimilarityImprovements" name="test_no_duplicate_pairs_with_bigram_and_block_overlap" time="0.001" /><testcase classname="tests.test_similarity_improvements.TestSimilarityImprovements" name="test_bigram_prepass_generates_pairs" time="0.002" /><testcase classname="tests.test_similarity_improvements.TestSimilarityImprovements" name="test_strategy_logging_includes_all_strategies" time="0.002" /><testcase classname="tests.test_similarity_refactor.TestSimilarityRefactor" name="test_pair_scores_no_mutation" time="0.003" /><testcase classname="tests.test_similarity_refactor.TestSimilarityRefactor" name="test_pair_scores_sort_order" time="0.003" /><testcase classname="tests.test_similarity_refactor.TestSimilarityRefactor" name="test_get_stop_tokens_from_config" time="0.000" /><testcase classname="tests.test_similarity_refactor.TestSimilarityRefactor" name="test_get_stop_tokens_default" time="0.000" /><testcase classname="tests.test_similarity_refactor.TestSimilarityRefactor" name="test_suffix_class_default_handling" time="0.003" /><testcase classname="tests.test_similarity_refactor.TestSimilarityRefactor" name="test_empty_dataframe_handling" time="0.001" /><testcase classname="tests.test_similarity_scores_columns" name="test_similarity_outputs_expected_columns" time="0.003" /><testcase classname="tests.test_similarity_shape_guard" name="test_shape_guard_catches_header_list" time="0.002" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_order_by_and_sort_expression_consistency[Group Size (Desc)-default-group_size]" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_order_by_and_sort_expression_consistency[Group Size (Desc)-group_details-group_size]" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_order_by_and_sort_expression_consistency[Group Size (Asc)-default-group_size]" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_order_by_and_sort_expression_consistency[Group Size (Asc)-group_details-group_size]" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_order_by_and_sort_expression_consistency[Max Score (Desc)-default-max_score]" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_order_by_and_sort_expression_consistency[Max Score (Desc)-group_details-max_score]" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_order_by_and_sort_expression_consistency[Max Score (Asc)-default-max_score]" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_order_by_and_sort_expression_consistency[Max Score (Asc)-group_details-max_score]" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_order_by_and_sort_expression_consistency[Account Name (Asc)-default-primary_name]" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_order_by_and_sort_expression_consistency[Account Name (Asc)-group_details-account_name]" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_order_by_and_sort_expression_consistency[Account Name (Desc)-default-primary_name]" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_order_by_and_sort_expression_consistency[Account Name (Desc)-group_details-account_name]" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_context_aware_account_name_mapping" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_all_sort_keys_have_consistent_mappings" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_sort_direction_consistency" time="0.000" /><testcase classname="tests.test_sort_context_consistency.TestSortContextConsistency" name="test_tiebreaker_consistency" time="0.000" /><testcase classname="tests.test_sort_spec.TestSortSpec" name="test_sort_spec_creation" time="0.000" /><testcase classname="tests.test_sort_spec.TestResolveSort" name="test_group_size_desc" time="0.000" /><testcase classname="tests.test_sort_spec.TestResolveSort" name="test_group_size_asc" time="0.000" /><testcase classname="tests.test_sort_spec.TestResolveSort" name="test_max_score_desc" time="0.000" /><testcase classname="tests.test_sort_spec.TestResolveSort" name="test_max_score_asc" time="0.000" /><testcase classname="tests.test_sort_spec.TestResolveSort" name="test_account_name_asc" time="0.000" /><testcase classname="tests.test_sort_spec.TestResolveSort" name="test_account_name_desc" time="0.000" /><testcase classname="tests.test_sort_spec.TestResolveSort" name="test_unknown_sort_key_fallback" time="0.001" /><testcase classname="tests.test_sort_spec.TestToDuckDBOrderBy" name="test_group_size_desc_to_duckdb" time="0.000" /><testcase classname="tests.test_sort_spec.TestToDuckDBOrderBy" name="test_max_score_asc_to_duckdb" time="0.000" /><testcase classname="tests.test_sort_spec.TestToPyArrowSortBy" name="test_group_size_desc_to_pyarrow" time="0.000" /><testcase classname="tests.test_sort_spec.TestToPyArrowSortBy" name="test_max_score_asc_to_pyarrow" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_stable_sort_key_group_size_desc" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_stable_sort_key_group_size_asc" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_stable_sort_key_max_score_desc" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_stable_sort_key_max_score_asc" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_stable_sort_key_account_name_asc" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_stable_sort_key_account_name_desc" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_stable_sort_key_default" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_coalesce_primary_name_with_value" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_coalesce_primary_name_none" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_coalesce_primary_name_empty_string" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_order_by_clause_group_size_desc" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_order_by_clause_group_size_asc" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_order_by_clause_max_score_desc" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_order_by_clause_max_score_asc" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_order_by_clause_account_name_asc" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_order_by_clause_account_name_desc" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_build_order_by_clause_default" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_validate_sort_key_valid_keys" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_validate_sort_key_invalid_keys" time="0.000" /><testcase classname="tests.test_sort_utils" name="test_validate_sort_key_case_sensitive" time="0.000" /><testcase classname="tests.test_state_utils" name="test_page_state_defaults" time="0.000" /><testcase classname="tests.test_state_utils" name="test_backend_state_defaults" time="0.000" /><testcase classname="tests.test_state_utils" name="test_details_state_defaults" time="0.000" /><testcase classname="tests.test_state_utils" name="test_explain_state_defaults" time="0.000" /><testcase classname="tests.test_state_utils" name="test_aliases_state_defaults" time="0.000" /><testcase classname="tests.test_state_utils" name="test_filters_state_defaults" time="0.000" /><testcase classname="tests.test_state_utils" name="test_cache_state_defaults" time="0.000" /><testcase classname="tests.test_state_utils" name="test_get_set_page_state" time="0.000" /><testcase classname="tests.test_state_utils" name="test_get_set_backend_state" time="0.000" /><testcase classname="tests.test_state_utils" name="test_get_set_details_state" time="0.000" /><testcase classname="tests.test_state_utils" name="test_get_set_explain_state" time="0.000" /><testcase classname="tests.test_state_utils" name="test_get_set_aliases_state" time="0.000" /><testcase classname="tests.test_state_utils" name="test_get_set_filters_state" time="0.000" /><testcase classname="tests.test_state_utils" name="test_get_set_cache_state" time="0.000" /><testcase classname="tests.test_state_utils" name="test_migrate_legacy_keys" time="0.000" /><testcase classname="tests.test_state_utils" name="test_clear_legacy_keys" time="0.000" /><testcase classname="tests.test_survivorship_equivalence.TestSurvivorshipEquivalence" name="test_singleton_groups_identical" time="0.012" /><testcase classname="tests.test_survivorship_equivalence.TestSurvivorshipEquivalence" name="test_multi_record_groups_identical" time="0.013" /><testcase classname="tests.test_survivorship_equivalence.TestSurvivorshipEquivalence" name="test_unassigned_groups_skipped" time="0.012" /><testcase classname="tests.test_survivorship_equivalence.TestSurvivorshipEquivalence" name="test_relationship_ranking_identical" time="0.011" /><testcase classname="tests.test_survivorship_equivalence.TestSurvivorshipEquivalence" name="test_tie_breaker_logic_identical" time="0.011" /><testcase classname="tests.test_survivorship_equivalence.TestSurvivorshipEquivalence" name="test_unknown_relationship_default_rank" time="0.006" /><testcase classname="tests.test_survivorship_equivalence.TestSurvivorshipEquivalence" name="test_feature_flag_control" time="0.012" /><testcase classname="tests.test_survivorship_equivalence.TestSurvivorshipEquivalence" name="test_deterministic_results" time="0.016" /></testsuite></testsuites>